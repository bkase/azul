{"id":"azul-3x2","title":"Use mlx-rs Optimizer for apply_gradients","description":"Currently apply_gradients is a no-op placeholder. Replace with Adam or SGD optimizer from mlx-rs::optimizers which properly updates parameters via parameters_mut(). Depends on azul-5dl.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:38:50.671351+01:00","updated_at":"2025-12-11T00:54:17.481777+01:00","closed_at":"2025-12-11T00:54:17.481777+01:00","dependencies":[{"issue_id":"azul-3x2","depends_on_id":"azul-5dl","type":"blocks","created_at":"2025-12-11T00:39:37.635734+01:00","created_by":"bkase"}]}
{"id":"azul-417","title":"Self-Play Training Pipeline","description":"Implement single-process self-play generation using AlphaZeroMctsAgent and AzulEnv, replay buffer of (observation, policy, value) training examples, and training loop using mlx-rs to optimize PolicyValueNet. Includes checkpointing and evaluation hooks. See history/selfplay-pipeline.md for full spec.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-10T22:21:59.530772+01:00","updated_at":"2025-12-10T23:53:06.453438+01:00","closed_at":"2025-12-10T23:53:06.453438+01:00","dependencies":[{"issue_id":"azul-417","depends_on_id":"azul-d2z","type":"blocks","created_at":"2025-12-10T22:28:52.992915+01:00","created_by":"bkase"}]}
{"id":"azul-417.1","title":"Create alphazero/ module directory structure","description":"Create crates/rl-env/src/alphazero/ directory with: mod.rs (module root), training.rs (Trainer + training loop), replay_buffer.rs (ReplayBuffer implementation), examples.rs (TrainingExample / move history helpers). Add 'mod alphazero;' to lib.rs.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:22:17.211744+01:00","updated_at":"2025-12-10T23:43:07.964217+01:00","closed_at":"2025-12-10T23:43:07.964217+01:00","dependencies":[{"issue_id":"azul-417.1","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:22:17.212789+01:00","created_by":"bkase"}]}
{"id":"azul-417.10","title":"Add select_action_and_policy to AlphaZeroMctsAgent","description":"Extend AlphaZeroMctsAgent with select_action_and_policy(\u0026mut self, input: \u0026AgentInput, rng: \u0026mut impl Rng) -\u003e MctsSearchResult. Runs MCTS search, returns both the selected action AND the full policy distribution from visit counts. Required for training to capture π target.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:23:43.548391+01:00","updated_at":"2025-12-10T23:43:56.156462+01:00","closed_at":"2025-12-10T23:43:56.156462+01:00","dependencies":[{"issue_id":"azul-417.10","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:23:43.549559+01:00","created_by":"bkase"},{"issue_id":"azul-417.10","depends_on_id":"azul-417.9","type":"blocks","created_at":"2025-12-10T22:29:47.634761+01:00","created_by":"bkase"},{"issue_id":"azul-417.10","depends_on_id":"azul-d2z.17","type":"blocks","created_at":"2025-12-10T22:29:52.760167+01:00","created_by":"bkase"}]}
{"id":"azul-417.11","title":"Implement compute_outcomes_from_scores helper","description":"In training.rs: fn compute_outcomes_from_scores(scores: \u0026[i16]) -\u003e Vec\u003cf32\u003e. Same semantics as RewardScheme::TerminalOnly: z_i = (score_i - mean(scores)) / 100.0. Converts final game scores to training values in ~[-1,1] range.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:23:49.983016+01:00","updated_at":"2025-12-10T23:44:01.257012+01:00","closed_at":"2025-12-10T23:44:01.257012+01:00","dependencies":[{"issue_id":"azul-417.11","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:23:49.983582+01:00","created_by":"bkase"}]}
{"id":"azul-417.12","title":"Define SelfPlayConfig struct","description":"In training.rs: Create SelfPlayConfig { max_moves: usize (safety cap), mcts_simulations: usize, dirichlet_alpha: f32, dirichlet_eps: f32, temp_cutoff_move: usize (temperature schedule switch) }. Configuration for self-play game generation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:23:55.930484+01:00","updated_at":"2025-12-10T23:44:06.36369+01:00","closed_at":"2025-12-10T23:44:06.36369+01:00","dependencies":[{"issue_id":"azul-417.12","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:23:55.931124+01:00","created_by":"bkase"}]}
{"id":"azul-417.13","title":"Implement self_play_game function","description":"In training.rs: fn self_play_game\u003cF, M\u003e(env: \u0026mut AzulEnv\u003cF\u003e, mcts_agent: \u0026mut AlphaZeroMctsAgent\u003cM\u003e, self_play_cfg: \u0026SelfPlayConfig, rng: \u0026mut impl Rng) -\u003e Vec\u003cTrainingExample\u003e. (1) Reset env, (2) Loop: build AgentInput, call select_action_and_policy, record PendingMove, step env, (3) At game end compute outcomes via scores, (4) Convert PendingMoves to TrainingExamples with value = outcomes[player].","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:24:02.070399+01:00","updated_at":"2025-12-10T23:44:13.17743+01:00","closed_at":"2025-12-10T23:44:13.17743+01:00","dependencies":[{"issue_id":"azul-417.13","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:24:02.071059+01:00","created_by":"bkase"},{"issue_id":"azul-417.13","depends_on_id":"azul-417.2","type":"blocks","created_at":"2025-12-10T22:30:00.756231+01:00","created_by":"bkase"},{"issue_id":"azul-417.13","depends_on_id":"azul-417.3","type":"blocks","created_at":"2025-12-10T22:30:05.88233+01:00","created_by":"bkase"},{"issue_id":"azul-417.13","depends_on_id":"azul-417.10","type":"blocks","created_at":"2025-12-10T22:30:10.99995+01:00","created_by":"bkase"},{"issue_id":"azul-417.13","depends_on_id":"azul-417.11","type":"blocks","created_at":"2025-12-10T22:30:16.120504+01:00","created_by":"bkase"},{"issue_id":"azul-417.13","depends_on_id":"azul-417.12","type":"blocks","created_at":"2025-12-10T22:30:21.243895+01:00","created_by":"bkase"}]}
{"id":"azul-417.14","title":"Define TrainerConfig struct","description":"In training.rs: Create TrainerConfig { num_players: u8, replay_capacity: usize, batch_size: usize, self_play_games_per_iter: usize, training_steps_per_iter: usize, num_iters: usize, learning_rate: f32, weight_decay: f32, value_loss_weight: f32, policy_loss_weight: f32, self_play: SelfPlayConfig, checkpoint_dir: Option\u003cPathBuf\u003e, eval_interval: usize }.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:24:29.383743+01:00","updated_at":"2025-12-10T23:44:18.283972+01:00","closed_at":"2025-12-10T23:44:18.283972+01:00","dependencies":[{"issue_id":"azul-417.14","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:24:29.384286+01:00","created_by":"bkase"},{"issue_id":"azul-417.14","depends_on_id":"azul-417.12","type":"blocks","created_at":"2025-12-10T22:30:27.234924+01:00","created_by":"bkase"}]}
{"id":"azul-417.15","title":"Define Trainer struct","description":"In training.rs: Create Trainer\u003cF, M\u003e where F: FeatureExtractor, M: PolicyValueModel { env: AzulEnv\u003cF\u003e, mcts_agent: AlphaZeroMctsAgent\u003cM\u003e, replay: ReplayBuffer, cfg: TrainerConfig, rng: rand::rngs::StdRng, optimizer: mlx_rs::optim::Adam }. Core training state holding all components.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:24:35.428935+01:00","updated_at":"2025-12-10T23:44:23.384562+01:00","closed_at":"2025-12-10T23:44:23.384562+01:00","dependencies":[{"issue_id":"azul-417.15","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:24:35.429505+01:00","created_by":"bkase"},{"issue_id":"azul-417.15","depends_on_id":"azul-417.14","type":"blocks","created_at":"2025-12-10T22:30:34.206992+01:00","created_by":"bkase"},{"issue_id":"azul-417.15","depends_on_id":"azul-417.8","type":"blocks","created_at":"2025-12-10T22:30:39.339405+01:00","created_by":"bkase"}]}
{"id":"azul-417.16","title":"Implement build_training_batch helper","description":"In training.rs: fn build_training_batch(examples: \u0026[\u0026TrainingExample]) -\u003e (Array, Array, Array). Returns (obs [B, obs_size], pi [B, ACTION_SPACE_SIZE], z [B]). Flatten example observations/policies/values into contiguous f32 vecs, then Array::from_slice with appropriate shapes.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:24:41.344094+01:00","updated_at":"2025-12-10T23:44:28.487418+01:00","closed_at":"2025-12-10T23:44:28.487418+01:00","dependencies":[{"issue_id":"azul-417.16","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:24:41.34467+01:00","created_by":"bkase"},{"issue_id":"azul-417.16","depends_on_id":"azul-417.2","type":"blocks","created_at":"2025-12-10T22:30:53.159744+01:00","created_by":"bkase"}]}
{"id":"azul-417.17","title":"Implement make_loss_fn for training","description":"In training.rs: fn make_loss_fn\u003cM: PolicyValueModel\u003e(model: \u0026M, value_loss_weight: f32, policy_loss_weight: f32) -\u003e impl Fn(\u0026[Array]) -\u003e Result\u003cArray, Exception\u003e. Policy loss: cross-entropy -sum(π * log_softmax(logits)). Value loss: MSE(pred, target). Total = policy_weight * policy_loss + value_weight * value_loss. Per MLX docs: inputs are [params..., obs, pi, z].","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:24:47.366685+01:00","updated_at":"2025-12-10T23:44:33.593612+01:00","closed_at":"2025-12-10T23:44:33.593612+01:00","dependencies":[{"issue_id":"azul-417.17","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:24:47.367276+01:00","created_by":"bkase"},{"issue_id":"azul-417.17","depends_on_id":"azul-417.39","type":"blocks","created_at":"2025-12-10T22:30:59.598215+01:00","created_by":"bkase"}]}
{"id":"azul-417.18","title":"Implement training_step function","description":"In training.rs: fn training_step\u003cM: PolicyValueModel\u003e(model: \u0026mut M, optimizer: \u0026mut Adam, batch: \u0026[\u0026TrainingExample], cfg: \u0026TrainerConfig) -\u003e Result\u003cf32, Exception\u003e. (1) Build batch arrays, (2) Assemble inputs [params..., obs, pi, z], (3) Call transforms::grad(loss_fn, argnums) where argnums = 0..param_count, (4) Apply gradients via optimizer, (5) Eval parameters, (6) Return loss.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:24:54.794701+01:00","updated_at":"2025-12-10T23:44:38.695425+01:00","closed_at":"2025-12-10T23:44:38.695425+01:00","dependencies":[{"issue_id":"azul-417.18","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:24:54.795243+01:00","created_by":"bkase"},{"issue_id":"azul-417.18","depends_on_id":"azul-417.16","type":"blocks","created_at":"2025-12-10T22:31:06.083999+01:00","created_by":"bkase"},{"issue_id":"azul-417.18","depends_on_id":"azul-417.17","type":"blocks","created_at":"2025-12-10T22:31:11.247174+01:00","created_by":"bkase"}]}
{"id":"azul-417.19","title":"Implement Trainer::run main training loop","description":"In training.rs: impl Trainer { fn run(\u0026mut self) -\u003e Result\u003c(), Exception\u003e }. For iter in 0..num_iters: (1) Self-play: generate self_play_games_per_iter games, extend replay buffer. (2) Training: for training_steps_per_iter: sample batch, call training_step. (3) Checkpoint: if checkpoint_dir set and iter % eval_interval == 0, save checkpoint.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:25:00.990715+01:00","updated_at":"2025-12-10T23:44:45.919333+01:00","closed_at":"2025-12-10T23:44:45.919333+01:00","dependencies":[{"issue_id":"azul-417.19","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:25:00.991226+01:00","created_by":"bkase"},{"issue_id":"azul-417.19","depends_on_id":"azul-417.15","type":"blocks","created_at":"2025-12-10T22:31:18.279828+01:00","created_by":"bkase"},{"issue_id":"azul-417.19","depends_on_id":"azul-417.13","type":"blocks","created_at":"2025-12-10T22:31:23.400504+01:00","created_by":"bkase"},{"issue_id":"azul-417.19","depends_on_id":"azul-417.18","type":"blocks","created_at":"2025-12-10T22:31:28.515751+01:00","created_by":"bkase"}]}
{"id":"azul-417.2","title":"Define TrainingExample struct","description":"In examples.rs: Create TrainingExample { observation: Observation, policy: Vec\u003cf32\u003e (len == ACTION_SPACE_SIZE), value: f32 }. Represents one (s, π, z) training sample in AlphaZero notation. observation is from acting player's perspective, policy is MCTS-improved distribution, value is final outcome from player's perspective (typically [-1,1]).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:22:23.721731+01:00","updated_at":"2025-12-10T23:43:13.100188+01:00","closed_at":"2025-12-10T23:43:13.100188+01:00","dependencies":[{"issue_id":"azul-417.2","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:22:23.72227+01:00","created_by":"bkase"},{"issue_id":"azul-417.2","depends_on_id":"azul-417.1","type":"blocks","created_at":"2025-12-10T22:29:00.311386+01:00","created_by":"bkase"}]}
{"id":"azul-417.20","title":"Implement Trainer::save_checkpoint","description":"In training.rs: fn save_checkpoint(\u0026self, dir: \u0026Path, iter: usize) -\u003e Result\u003c(), io::Error\u003e. Serialize model parameters to checkpoint file (e.g. checkpoint_iter.bin). Use PolicyValueModel::save or equivalent. Basic implementation - can be enhanced later.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:25:08.199908+01:00","updated_at":"2025-12-10T23:44:51.024349+01:00","closed_at":"2025-12-10T23:44:51.024349+01:00","dependencies":[{"issue_id":"azul-417.20","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:25:08.200457+01:00","created_by":"bkase"},{"issue_id":"azul-417.20","depends_on_id":"azul-417.15","type":"blocks","created_at":"2025-12-10T22:31:34.89258+01:00","created_by":"bkase"}]}
{"id":"azul-417.21","title":"Create train_alphazero.rs CLI binary","description":"Create crates/rl-env/src/bin/train_alphazero.rs. Parse CLI args or config file, create EnvConfig with num_players/TerminalOnly/include_full_state, create AzulEnv, PolicyValueNet, AlphaZeroMctsAgent, ReplayBuffer, optimizer. Instantiate Trainer and call run(). Add [[bin]] entry to Cargo.toml.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:25:20.867155+01:00","updated_at":"2025-12-10T23:51:18.336361+01:00","closed_at":"2025-12-10T23:51:18.336361+01:00","dependencies":[{"issue_id":"azul-417.21","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:25:20.867776+01:00","created_by":"bkase"},{"issue_id":"azul-417.21","depends_on_id":"azul-417.19","type":"blocks","created_at":"2025-12-10T22:31:41.418389+01:00","created_by":"bkase"},{"issue_id":"azul-417.21","depends_on_id":"azul-417.20","type":"blocks","created_at":"2025-12-10T22:31:46.54606+01:00","created_by":"bkase"}]}
{"id":"azul-417.22","title":"Test: ReplayBuffer push and len","description":"test_replay_buffer_push_and_len: Create buffer capacity 3. Push 2 samples -\u003e len() == 2. Push 3rd sample -\u003e len() == 3.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:25:40.991696+01:00","updated_at":"2025-12-10T23:44:56.127135+01:00","closed_at":"2025-12-10T23:44:56.127135+01:00","dependencies":[{"issue_id":"azul-417.22","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:25:40.992263+01:00","created_by":"bkase"},{"issue_id":"azul-417.22","depends_on_id":"azul-417.6","type":"blocks","created_at":"2025-12-10T22:32:28.347455+01:00","created_by":"bkase"}]}
{"id":"azul-417.23","title":"Test: ReplayBuffer overwrite oldest","description":"test_replay_buffer_overwrite_oldest: Capacity 2; push A, B; verify order. Push C; buffer should contain {B, C}, not A. Tests ring buffer wrap-around.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:25:47.330751+01:00","updated_at":"2025-12-10T23:45:01.230417+01:00","closed_at":"2025-12-10T23:45:01.230417+01:00","dependencies":[{"issue_id":"azul-417.23","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:25:47.331747+01:00","created_by":"bkase"},{"issue_id":"azul-417.23","depends_on_id":"azul-417.6","type":"blocks","created_at":"2025-12-10T22:32:33.473507+01:00","created_by":"bkase"}]}
{"id":"azul-417.24","title":"Test: ReplayBuffer sample returns valid refs","description":"test_replay_buffer_sample_returns_valid_refs: Fill buffer; sample 5 times; each sample is one of stored items, never out-of-bounds. Test empty case panics with assert.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:25:53.23656+01:00","updated_at":"2025-12-10T23:45:06.334949+01:00","closed_at":"2025-12-10T23:45:06.334949+01:00","dependencies":[{"issue_id":"azul-417.24","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:25:53.237089+01:00","created_by":"bkase"},{"issue_id":"azul-417.24","depends_on_id":"azul-417.8","type":"blocks","created_at":"2025-12-10T22:32:38.606071+01:00","created_by":"bkase"}]}
{"id":"azul-417.25","title":"Test: build_training_batch shapes","description":"test_build_training_batch_shapes: Create synthetic TrainingExamples with known obs_size and ACTION_SPACE_SIZE. Build batch; assert obs.shape() == [B, obs_size], pi.shape() == [B, ACTION_SPACE_SIZE], z.shape() == [B].","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:26:02.28704+01:00","updated_at":"2025-12-10T23:45:11.444199+01:00","closed_at":"2025-12-10T23:45:11.444199+01:00","dependencies":[{"issue_id":"azul-417.25","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:26:02.287842+01:00","created_by":"bkase"},{"issue_id":"azul-417.25","depends_on_id":"azul-417.16","type":"blocks","created_at":"2025-12-10T22:32:44.85273+01:00","created_by":"bkase"}]}
{"id":"azul-417.26","title":"Test: compute_outcomes_from_scores zero-sum","description":"test_compute_outcomes_from_scores_zero_sum: Provide scores [10, 20]. Compute outcomes; check sum outcomes ≈ 0, higher-score outcome \u003e 0, lower \u003c 0.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:26:08.454323+01:00","updated_at":"2025-12-10T23:45:18.452632+01:00","closed_at":"2025-12-10T23:45:18.452632+01:00","dependencies":[{"issue_id":"azul-417.26","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:26:08.45488+01:00","created_by":"bkase"},{"issue_id":"azul-417.26","depends_on_id":"azul-417.11","type":"blocks","created_at":"2025-12-10T22:32:51.159863+01:00","created_by":"bkase"}]}
{"id":"azul-417.27","title":"Test: compute_outcomes multi-player","description":"test_compute_outcomes_multi_player: Scores [10, 10, 10]; outcomes all ≈ 0. Tests tied game produces neutral values.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:26:15.384578+01:00","updated_at":"2025-12-10T23:45:23.555262+01:00","closed_at":"2025-12-10T23:45:23.555262+01:00","dependencies":[{"issue_id":"azul-417.27","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:26:15.385227+01:00","created_by":"bkase"},{"issue_id":"azul-417.27","depends_on_id":"azul-417.11","type":"blocks","created_at":"2025-12-10T22:32:56.281178+01:00","created_by":"bkase"}]}
{"id":"azul-417.28","title":"Create StubPolicyValueModel for testing","description":"In alphazero/tests or training.rs: Create StubPolicyValueModel that always returns uniform logits and zero value. Allows testing MCTS and self-play logic independently of real neural network.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:26:34.405762+01:00","updated_at":"2025-12-10T23:48:14.109087+01:00","closed_at":"2025-12-10T23:48:14.109087+01:00","dependencies":[{"issue_id":"azul-417.28","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:26:34.406367+01:00","created_by":"bkase"},{"issue_id":"azul-417.28","depends_on_id":"azul-417.1","type":"blocks","created_at":"2025-12-10T22:33:02.207345+01:00","created_by":"bkase"}]}
{"id":"azul-417.29","title":"Test: self_play generates examples","description":"test_self_play_generates_examples: Configure EnvConfig with num_players=2, use StubPolicyValueModel, small mcts_simulations. Run self_play_game with large max_moves. Assert: examples.len() \u003e 0, each policy.len() == ACTION_SPACE_SIZE, each policy sums to ~1, each value in reasonable bounds [-2, 2].","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:26:40.436043+01:00","updated_at":"2025-12-10T23:48:19.251836+01:00","closed_at":"2025-12-10T23:48:19.251836+01:00","dependencies":[{"issue_id":"azul-417.29","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:26:40.436618+01:00","created_by":"bkase"},{"issue_id":"azul-417.29","depends_on_id":"azul-417.13","type":"blocks","created_at":"2025-12-10T22:33:09.053829+01:00","created_by":"bkase"},{"issue_id":"azul-417.29","depends_on_id":"azul-417.28","type":"blocks","created_at":"2025-12-10T22:33:14.166587+01:00","created_by":"bkase"}]}
{"id":"azul-417.3","title":"Define PendingMove struct","description":"In examples.rs: Create PendingMove { player: azul_engine::PlayerIdx, observation: Observation, policy: Vec\u003cf32\u003e }. Internal helper for recording moves during a game before we know the final outcome. Converted to TrainingExample when game ends.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:22:30.651088+01:00","updated_at":"2025-12-10T23:43:18.227481+01:00","closed_at":"2025-12-10T23:43:18.227481+01:00","dependencies":[{"issue_id":"azul-417.3","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:22:30.65203+01:00","created_by":"bkase"},{"issue_id":"azul-417.3","depends_on_id":"azul-417.1","type":"blocks","created_at":"2025-12-10T22:29:05.440934+01:00","created_by":"bkase"}]}
{"id":"azul-417.30","title":"Test: self_play respects max_moves","description":"test_self_play_respects_max_moves: Set max_moves = 5. Ensure examples.len() \u003c= 5. Tests safety cap prevents infinite games.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:26:48.204005+01:00","updated_at":"2025-12-10T23:48:24.383899+01:00","closed_at":"2025-12-10T23:48:24.383899+01:00","dependencies":[{"issue_id":"azul-417.30","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:26:48.204515+01:00","created_by":"bkase"},{"issue_id":"azul-417.30","depends_on_id":"azul-417.13","type":"blocks","created_at":"2025-12-10T22:33:20.924125+01:00","created_by":"bkase"},{"issue_id":"azul-417.30","depends_on_id":"azul-417.28","type":"blocks","created_at":"2025-12-10T22:33:26.047312+01:00","created_by":"bkase"}]}
{"id":"azul-417.31","title":"Test: self_play determinism with stub model","description":"test_self_play_determinism_with_stub_model: Use fixed StdRng seed and stub model. Run self_play_game twice. Verify sequence of actions (or policy vectors and values) is identical between runs.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:26:54.104941+01:00","updated_at":"2025-12-10T23:48:29.519514+01:00","closed_at":"2025-12-10T23:48:29.519514+01:00","dependencies":[{"issue_id":"azul-417.31","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:26:54.105472+01:00","created_by":"bkase"},{"issue_id":"azul-417.31","depends_on_id":"azul-417.13","type":"blocks","created_at":"2025-12-10T22:33:32.522669+01:00","created_by":"bkase"},{"issue_id":"azul-417.31","depends_on_id":"azul-417.28","type":"blocks","created_at":"2025-12-10T22:33:37.642556+01:00","created_by":"bkase"}]}
{"id":"azul-417.32","title":"Test: loss_fn runs on toy batch","description":"test_loss_fn_runs_on_toy_batch: Build toy batch with 2 examples, simple policies (one-hot) and values. Build tiny PolicyValueModel (e.g., linear layer). Call training_step once; assert returns Ok(loss) and loss is finite (not NaN or inf).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:27:10.003983+01:00","updated_at":"2025-12-10T23:52:24.138065+01:00","closed_at":"2025-12-10T23:52:24.138065+01:00","dependencies":[{"issue_id":"azul-417.32","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:27:10.004573+01:00","created_by":"bkase"},{"issue_id":"azul-417.32","depends_on_id":"azul-417.18","type":"blocks","created_at":"2025-12-10T22:33:52.800128+01:00","created_by":"bkase"}]}
{"id":"azul-417.33","title":"Test: training_step updates model parameters","description":"test_training_step_updates_model_parameters: Clone model params before training. Run training_step on toy batch. Retrieve params after; assert at least one parameter array differs from before (norm difference \u003e 0).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:27:16.732643+01:00","updated_at":"2025-12-10T23:52:29.271949+01:00","closed_at":"2025-12-10T23:52:29.271949+01:00","dependencies":[{"issue_id":"azul-417.33","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:27:16.733137+01:00","created_by":"bkase"},{"issue_id":"azul-417.33","depends_on_id":"azul-417.18","type":"blocks","created_at":"2025-12-10T22:33:57.935037+01:00","created_by":"bkase"}]}
{"id":"azul-417.34","title":"Test: training_step gradient shapes","description":"test_training_step_gradient_shapes: Internal helper - call transforms::grad directly on loss fn with known param shapes; ensure gradient arrays have the same shapes as parameters.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:27:22.823155+01:00","updated_at":"2025-12-10T23:52:34.406283+01:00","closed_at":"2025-12-10T23:52:34.406283+01:00","dependencies":[{"issue_id":"azul-417.34","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:27:22.824015+01:00","created_by":"bkase"},{"issue_id":"azul-417.34","depends_on_id":"azul-417.17","type":"blocks","created_at":"2025-12-10T22:34:03.063071+01:00","created_by":"bkase"}]}
{"id":"azul-417.35","title":"Test: trainer runs small config","description":"test_trainer_runs_small_config: Configure TrainerConfig with num_iters=2, self_play_games_per_iter=1, training_steps_per_iter=1, small replay_capacity/batch_size. Use stub model + small MCTS. Run trainer.run(). Assert: no panic, replay.len() \u003e 0, model params changed vs initial.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:27:40.833467+01:00","updated_at":"2025-12-10T23:52:39.542583+01:00","closed_at":"2025-12-10T23:52:39.542583+01:00","dependencies":[{"issue_id":"azul-417.35","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:27:40.834034+01:00","created_by":"bkase"},{"issue_id":"azul-417.35","depends_on_id":"azul-417.19","type":"blocks","created_at":"2025-12-10T22:34:10.477747+01:00","created_by":"bkase"},{"issue_id":"azul-417.35","depends_on_id":"azul-417.28","type":"blocks","created_at":"2025-12-10T22:34:15.609043+01:00","created_by":"bkase"}]}
{"id":"azul-417.36","title":"Test: trainer determinism with stub model","description":"test_trainer_determinism_with_stub_model: Fix RNG seed and use stub model \u0026 MCTS config with no randomness except RNG. Run training loop for 1 iteration twice from same initial state. Confirm: sequence of self-play game lengths identical, final model parameters identical (within numerical tolerance).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:27:49.974992+01:00","updated_at":"2025-12-10T23:52:44.676046+01:00","closed_at":"2025-12-10T23:52:44.676046+01:00","dependencies":[{"issue_id":"azul-417.36","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:27:49.975534+01:00","created_by":"bkase"},{"issue_id":"azul-417.36","depends_on_id":"azul-417.19","type":"blocks","created_at":"2025-12-10T22:34:22.725065+01:00","created_by":"bkase"},{"issue_id":"azul-417.36","depends_on_id":"azul-417.28","type":"blocks","created_at":"2025-12-10T22:34:27.854721+01:00","created_by":"bkase"}]}
{"id":"azul-417.37","title":"Test: self_play episode runtime under threshold","description":"test_self_play_episode_runtime_under_threshold: Run one self-play game with some mcts_simulations and assert it completes within a sane time bound (e.g., 1 second) in CI. Helps catch pathological recursion/loops. Optional sanity check.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-10T22:27:58.31809+01:00","updated_at":"2025-12-10T23:52:49.744122+01:00","closed_at":"2025-12-10T23:52:49.744122+01:00","dependencies":[{"issue_id":"azul-417.37","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:27:58.318659+01:00","created_by":"bkase"},{"issue_id":"azul-417.37","depends_on_id":"azul-417.13","type":"blocks","created_at":"2025-12-10T22:34:34.464467+01:00","created_by":"bkase"}]}
{"id":"azul-417.38","title":"Run cargo test for training pipeline","description":"Run 'cargo test -p azul-rl-env' to verify all training pipeline tests pass. This is the final validation step for the self-play training implementation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:28:16.667995+01:00","updated_at":"2025-12-10T23:52:54.868839+01:00","closed_at":"2025-12-10T23:52:54.868839+01:00","dependencies":[{"issue_id":"azul-417.38","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:28:16.668472+01:00","created_by":"bkase"},{"issue_id":"azul-417.38","depends_on_id":"azul-417.21","type":"blocks","created_at":"2025-12-10T22:34:40.992599+01:00","created_by":"bkase"}]}
{"id":"azul-417.39","title":"Extend PolicyValueModel trait for training","description":"Extend PolicyValueModel trait with training-required methods: param_count() -\u003e usize, parameters() -\u003e Vec\u003cArray\u003e, forward_with_params(params: \u0026[Array], obs: \u0026Array) -\u003e (Array, Array), apply_gradients(\u0026mut self, optimizer: \u0026mut Adam, grads: \u0026[Array]) -\u003e Result\u003c()\u003e, eval_parameters(\u0026self) -\u003e Result\u003c()\u003e. These enable MLX autodiff training loop.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:28:23.133604+01:00","updated_at":"2025-12-10T23:51:23.468168+01:00","closed_at":"2025-12-10T23:51:23.468168+01:00","dependencies":[{"issue_id":"azul-417.39","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:28:23.134352+01:00","created_by":"bkase"},{"issue_id":"azul-417.39","depends_on_id":"azul-d2z.4","type":"blocks","created_at":"2025-12-10T22:31:58.389491+01:00","created_by":"bkase"}]}
{"id":"azul-417.4","title":"Define ReplayBuffer struct","description":"In replay_buffer.rs: Create ReplayBuffer { capacity: usize, data: Vec\u003cTrainingExample\u003e, write_index: usize, is_full: bool }. Ring buffer storage - data length is min(total_seen, capacity), write_index points to next write location.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:22:49.403118+01:00","updated_at":"2025-12-10T23:43:23.352318+01:00","closed_at":"2025-12-10T23:43:23.352318+01:00","dependencies":[{"issue_id":"azul-417.4","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:22:49.404249+01:00","created_by":"bkase"},{"issue_id":"azul-417.4","depends_on_id":"azul-417.2","type":"blocks","created_at":"2025-12-10T22:29:11.763226+01:00","created_by":"bkase"}]}
{"id":"azul-417.40","title":"Implement training methods for AlphaZeroNet","description":"Implement the training-required methods from extended PolicyValueModel trait for AlphaZeroNet: param_count, parameters, forward_with_params, apply_gradients, eval_parameters. Enable MLX autodiff to compute gradients and update weights.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:28:31.644912+01:00","updated_at":"2025-12-10T23:51:28.600407+01:00","closed_at":"2025-12-10T23:51:28.600407+01:00","dependencies":[{"issue_id":"azul-417.40","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:28:31.645884+01:00","created_by":"bkase"},{"issue_id":"azul-417.40","depends_on_id":"azul-417.39","type":"blocks","created_at":"2025-12-10T22:32:06.691687+01:00","created_by":"bkase"},{"issue_id":"azul-417.40","depends_on_id":"azul-d2z.23","type":"blocks","created_at":"2025-12-10T22:32:11.824639+01:00","created_by":"bkase"}]}
{"id":"azul-417.5","title":"Implement ReplayBuffer::new and len/is_empty","description":"Implement: new(capacity: usize) -\u003e Self initializes empty buffer. len() returns data.len(). is_empty() returns data.is_empty().","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:22:55.978488+01:00","updated_at":"2025-12-10T23:43:28.478664+01:00","closed_at":"2025-12-10T23:43:28.478664+01:00","dependencies":[{"issue_id":"azul-417.5","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:22:55.978981+01:00","created_by":"bkase"},{"issue_id":"azul-417.5","depends_on_id":"azul-417.4","type":"blocks","created_at":"2025-12-10T22:29:18.411092+01:00","created_by":"bkase"}]}
{"id":"azul-417.6","title":"Implement ReplayBuffer::push","description":"Implement push(\u0026mut self, example: TrainingExample). If data.len() \u003c capacity: data.push(example). Else: data[write_index] = example and write_index = (write_index + 1) % capacity. Overwrites oldest when full.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:23:02.494303+01:00","updated_at":"2025-12-10T23:43:33.593766+01:00","closed_at":"2025-12-10T23:43:33.593766+01:00","dependencies":[{"issue_id":"azul-417.6","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:23:02.494799+01:00","created_by":"bkase"},{"issue_id":"azul-417.6","depends_on_id":"azul-417.5","type":"blocks","created_at":"2025-12-10T22:29:23.536807+01:00","created_by":"bkase"}]}
{"id":"azul-417.7","title":"Implement ReplayBuffer::extend","description":"Implement extend\u003cI: IntoIterator\u003cItem = TrainingExample\u003e\u003e(\u0026mut self, it: I). Calls push for each item. Convenience method for adding many examples from a completed game.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:23:08.869606+01:00","updated_at":"2025-12-10T23:43:40.841532+01:00","closed_at":"2025-12-10T23:43:40.841532+01:00","dependencies":[{"issue_id":"azul-417.7","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:23:08.870161+01:00","created_by":"bkase"},{"issue_id":"azul-417.7","depends_on_id":"azul-417.6","type":"blocks","created_at":"2025-12-10T22:29:28.666917+01:00","created_by":"bkase"}]}
{"id":"azul-417.8","title":"Implement ReplayBuffer::sample","description":"Implement sample\u003c'a\u003e(\u0026'a self, rng: \u0026mut impl Rng, batch_size: usize) -\u003e Vec\u003c\u0026'a TrainingExample\u003e. Assert \\!is_empty(). Uniformly sample batch_size examples with replacement. For i in 0..batch_size: idx = rng.random_range(0..len), push \u0026data[idx].","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:23:16.087121+01:00","updated_at":"2025-12-10T23:43:45.949552+01:00","closed_at":"2025-12-10T23:43:45.949552+01:00","dependencies":[{"issue_id":"azul-417.8","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:23:16.08766+01:00","created_by":"bkase"},{"issue_id":"azul-417.8","depends_on_id":"azul-417.5","type":"blocks","created_at":"2025-12-10T22:29:33.792093+01:00","created_by":"bkase"}]}
{"id":"azul-417.9","title":"Define MctsSearchResult struct","description":"In mcts.rs (or training.rs): Create MctsSearchResult { action: ActionId, policy: Vec\u003cf32\u003e (len == ACTION_SPACE_SIZE) }. Output of MCTS search at root - action is selected move, policy is visit-count-based distribution over all actions (normalized).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:23:37.404895+01:00","updated_at":"2025-12-10T23:43:51.054409+01:00","closed_at":"2025-12-10T23:43:51.054409+01:00","dependencies":[{"issue_id":"azul-417.9","depends_on_id":"azul-417","type":"parent-child","created_at":"2025-12-10T22:23:37.40567+01:00","created_by":"bkase"}]}
{"id":"azul-5dl","title":"Implement ModuleParameters for AlphaZeroNet","description":"AlphaZeroNet currently returns dummy zero arrays from parameters(). Need to properly implement ModuleParameters trait by delegating to trunk, policy_head, and value_head Sequential modules. This enables using mlx-rs optimizer system.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:38:16.943999+01:00","updated_at":"2025-12-11T00:44:22.074628+01:00","closed_at":"2025-12-11T00:44:22.074628+01:00"}
{"id":"azul-85d","title":"RL Environment \u0026 Agent API","description":"Build reinforcement learning environment interface and agent API for Azul game","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-09T21:14:33.06036+01:00","updated_at":"2025-12-10T17:46:07.575561+01:00","closed_at":"2025-12-10T17:46:07.575561+01:00","labels":["api","environment","rl"]}
{"id":"azul-85d.1","title":"Define ActionId and Reward type aliases","description":"Create core RL type aliases in new rl_env module:\n- `pub type ActionId = u16;` (0..ACTION_SPACE_SIZE-1)\n- `pub type Reward = f32;`\n- `pub type Observation = mlx_rs::Array;` (f32, shape [obs_size])\nThese are the fundamental types that all other RL components will use. Observation invariant: rank 1, shape [obs_size], dtype f32.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:12:56.452959+01:00","updated_at":"2025-12-10T17:39:12.118954+01:00","closed_at":"2025-12-10T17:39:12.118954+01:00","dependencies":[{"issue_id":"azul-85d.1","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:12:56.453973+01:00","created_by":"bkase"},{"issue_id":"azul-85d.1","depends_on_id":"azul-85d.33","type":"blocks","created_at":"2025-12-10T17:19:08.219532+01:00","created_by":"bkase"}]}
{"id":"azul-85d.10","title":"Define FeatureExtractor trait","description":"Create FeatureExtractor trait for converting GameState to MLX Array observation:\n```rust\npub trait FeatureExtractor {\n    fn obs_size(\u0026self) -\u003e usize;  // Length of flattened observation vector\n    fn encode(\u0026self, state: \u0026GameState, player: PlayerIdx) -\u003e Observation;\n}\n```\nRequirements:\n- encode() is deterministic given (state, player)\n- Returns Array with rank 1, shape [obs_size()], dtype f32\n- No side effects or internal randomness\n- Must encode: boards, walls, pattern lines, floors, whose turn, factory state, center pool","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:14:49.280936+01:00","updated_at":"2025-12-10T17:40:01.130946+01:00","closed_at":"2025-12-10T17:40:01.130946+01:00","dependencies":[{"issue_id":"azul-85d.10","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:14:49.28153+01:00","created_by":"bkase"},{"issue_id":"azul-85d.10","depends_on_id":"azul-85d.1","type":"blocks","created_at":"2025-12-10T17:20:04.534958+01:00","created_by":"bkase"}]}
{"id":"azul-85d.11","title":"Implement create_zero_observation helper","description":"Create helper function for zero-filled observations:\n```rust\npub fn create_zero_observation(obs_size: usize) -\u003e Observation\n```\n- Returns MLX Array of zeros with shape [obs_size] and dtype f32\n- Used for unused player slots (indices \u003e= num_players)\n- Simple wrapper around MLX array creation API","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T17:14:55.812527+01:00","updated_at":"2025-12-10T17:40:06.299362+01:00","closed_at":"2025-12-10T17:40:06.299362+01:00","dependencies":[{"issue_id":"azul-85d.11","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:14:55.813311+01:00","created_by":"bkase"},{"issue_id":"azul-85d.11","depends_on_id":"azul-85d.10","type":"blocks","created_at":"2025-12-10T17:20:09.655411+01:00","created_by":"bkase"}]}
{"id":"azul-85d.12","title":"Implement concrete FeatureExtractor","description":"Implement a concrete FeatureExtractor (e.g., BasicFeatureExtractor):\nEncode at minimum:\n- All 5 factory displays (4 tiles each × 5 colors = one-hot or counts)\n- Center pool contents (color counts + first player marker)\n- For each player: pattern lines (5 rows, color + count), wall (5×5 binary), floor line (7 slots)\n- Current player indicator, starting player next round indicator\n- Scores (normalized)\nConsider multi-channel binary planes flattened to 1D. Document obs_size calculation.\nTarget: ~500-1500 features depending on encoding density.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:15:02.98382+01:00","updated_at":"2025-12-10T17:40:11.451928+01:00","closed_at":"2025-12-10T17:40:11.451928+01:00","dependencies":[{"issue_id":"azul-85d.12","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:15:02.984348+01:00","created_by":"bkase"},{"issue_id":"azul-85d.12","depends_on_id":"azul-85d.10","type":"blocks","created_at":"2025-12-10T17:20:14.789577+01:00","created_by":"bkase"},{"issue_id":"azul-85d.12","depends_on_id":"azul-85d.11","type":"blocks","created_at":"2025-12-10T17:20:19.920643+01:00","created_by":"bkase"}]}
{"id":"azul-85d.13","title":"Implement FeatureExtractor tests","description":"Tests for FeatureExtractor implementation:\n1. Shape test: For arbitrary reachable GameStates and players, obs.shape == [obs_size()]\n2. Dtype test: obs.dtype() == f32\n3. Rank test: obs.rank() == 1\n4. Determinism test: encode(state, player) == encode(state, player) on repeated calls\n5. Player perspective test: encode(state, 0) != encode(state, 1) when players have different boards\n6. Boundary test: obs_size() matches actual encoded length","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T17:15:09.884065+01:00","updated_at":"2025-12-10T17:45:31.061689+01:00","closed_at":"2025-12-10T17:45:31.061689+01:00","dependencies":[{"issue_id":"azul-85d.13","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:15:09.884597+01:00","created_by":"bkase"},{"issue_id":"azul-85d.13","depends_on_id":"azul-85d.12","type":"blocks","created_at":"2025-12-10T17:20:25.047291+01:00","created_by":"bkase"}]}
{"id":"azul-85d.14","title":"Define generic Environment trait","description":"Create generic Environment trait for RL:\n```rust\npub trait Environment {\n    type ObservationType;\n    type ActionType;\n    type RewardType;\n\n    fn reset(\u0026mut self, rng: \u0026mut impl Rng) -\u003e EnvStep\u003cSelf::ObservationType, Self::RewardType\u003e;\n    \n    fn step(\u0026mut self, action: Self::ActionType, rng: \u0026mut impl Rng) \n        -\u003e Result\u003cEnvStep\u003cSelf::ObservationType, Self::RewardType\u003e, StepError\u003e;\n}\n```\nThis trait abstracts the RL environment interface, making it reusable for other games.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:15:30.916774+01:00","updated_at":"2025-12-10T17:40:24.456827+01:00","closed_at":"2025-12-10T17:40:24.456827+01:00","dependencies":[{"issue_id":"azul-85d.14","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:15:30.917291+01:00","created_by":"bkase"},{"issue_id":"azul-85d.14","depends_on_id":"azul-85d.5","type":"blocks","created_at":"2025-12-10T17:20:34.357374+01:00","created_by":"bkase"},{"issue_id":"azul-85d.14","depends_on_id":"azul-85d.4","type":"blocks","created_at":"2025-12-10T17:20:39.490574+01:00","created_by":"bkase"}]}
{"id":"azul-85d.15","title":"Implement AzulEnv struct","description":"Create AzulEnv\u003cF: FeatureExtractor\u003e struct:\n```rust\npub struct AzulEnv\u003cF: FeatureExtractor\u003e {\n    pub game_state: GameState,\n    pub config: EnvConfig,\n    pub features: F,\n    pub last_action: Option\u003cActionId\u003e,\n    pub done: bool,\n}\n```\nInvariants:\n- game_state.num_players == config.num_players\n- done == (game_state.phase == Phase::GameOver)\n- If !done, then game_state.phase == Phase::FactoryOffer","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:15:37.306358+01:00","updated_at":"2025-12-10T17:40:29.621997+01:00","closed_at":"2025-12-10T17:40:29.621997+01:00","dependencies":[{"issue_id":"azul-85d.15","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:15:37.306987+01:00","created_by":"bkase"},{"issue_id":"azul-85d.15","depends_on_id":"azul-85d.10","type":"blocks","created_at":"2025-12-10T17:20:44.619256+01:00","created_by":"bkase"},{"issue_id":"azul-85d.15","depends_on_id":"azul-85d.3","type":"blocks","created_at":"2025-12-10T17:20:49.730776+01:00","created_by":"bkase"}]}
{"id":"azul-85d.16","title":"Implement AzulEnv::build_legal_action_mask","description":"Implement helper method for AzulEnv:\n```rust\nimpl\u003cF: FeatureExtractor\u003e AzulEnv\u003cF\u003e {\n    fn build_legal_action_mask(\u0026self) -\u003e Vec\u003cbool\u003e {\n        let mut mask = vec![false; ACTION_SPACE_SIZE];\n        for action in legal_actions(\u0026self.game_state) {\n            let id = ActionEncoder::encode(\u0026action) as usize;\n            mask[id] = true;\n        }\n        mask\n    }\n}\n```\nConverts engine's legal_actions() Vec\u003cAction\u003e into fixed-size boolean mask over action space.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:15:44.662721+01:00","updated_at":"2025-12-10T17:40:34.791546+01:00","closed_at":"2025-12-10T17:40:34.791546+01:00","dependencies":[{"issue_id":"azul-85d.16","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:15:44.663313+01:00","created_by":"bkase"},{"issue_id":"azul-85d.16","depends_on_id":"azul-85d.15","type":"blocks","created_at":"2025-12-10T17:20:54.868472+01:00","created_by":"bkase"},{"issue_id":"azul-85d.16","depends_on_id":"azul-85d.7","type":"blocks","created_at":"2025-12-10T17:21:00.005271+01:00","created_by":"bkase"}]}
{"id":"azul-85d.17","title":"Implement AzulEnv::new constructor","description":"Implement AzulEnv constructor:\n```rust\nimpl\u003cF: FeatureExtractor\u003e AzulEnv\u003cF\u003e {\n    pub fn new(config: EnvConfig, features: F) -\u003e Self {\n        // Create with placeholder game_state (will be initialized on reset)\n        // Or require rng and initialize immediately\n    }\n}\n```\nConsider: should constructor take rng and call reset(), or leave uninitialized until first reset()?","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:15:51.801744+01:00","updated_at":"2025-12-10T17:40:39.953199+01:00","closed_at":"2025-12-10T17:40:39.953199+01:00","dependencies":[{"issue_id":"azul-85d.17","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:15:51.802305+01:00","created_by":"bkase"},{"issue_id":"azul-85d.17","depends_on_id":"azul-85d.15","type":"blocks","created_at":"2025-12-10T17:21:05.147443+01:00","created_by":"bkase"}]}
{"id":"azul-85d.18","title":"Implement Environment::reset for AzulEnv","description":"Implement reset() for AzulEnv\u003cF\u003e:\n1. Create fresh GameState via new_game(num_players, starting_player, rng)\n2. Set last_action = None, done = false\n3. Build per-player observations: for idx 0..MAX_PLAYERS, if idx \u003c num_players then features.encode(state, idx), else create_zero_observation()\n4. Set rewards = [0.0; MAX_PLAYERS]\n5. Build legal_action_mask via build_legal_action_mask()\n6. Optionally clone state if include_full_state_in_step\n7. Return EnvStep with all fields populated","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:16:16.13087+01:00","updated_at":"2025-12-10T17:40:45.116728+01:00","closed_at":"2025-12-10T17:40:45.116728+01:00","dependencies":[{"issue_id":"azul-85d.18","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:16:16.13139+01:00","created_by":"bkase"},{"issue_id":"azul-85d.18","depends_on_id":"azul-85d.14","type":"blocks","created_at":"2025-12-10T17:21:21.122183+01:00","created_by":"bkase"},{"issue_id":"azul-85d.18","depends_on_id":"azul-85d.16","type":"blocks","created_at":"2025-12-10T17:21:26.252569+01:00","created_by":"bkase"},{"issue_id":"azul-85d.18","depends_on_id":"azul-85d.12","type":"blocks","created_at":"2025-12-10T17:21:31.384505+01:00","created_by":"bkase"}]}
{"id":"azul-85d.19","title":"Implement Environment::step for AzulEnv","description":"Implement step() for AzulEnv\u003cF\u003e:\n1. Check self.done -\u003e return Err(StepError::EpisodeDone)\n2. Decode action_id via ActionEncoder::decode()\n3. Check legality via build_legal_action_mask() -\u003e return Err(StepError::IllegalAction) if false\n4. Record prev_scores for all players\n5. Apply action via apply_action(state, action, rng)\n6. Compute rewards based on RewardScheme (DenseScoreDelta or TerminalOnly)\n7. Update done flag based on phase\n8. Build new observations for all players\n9. Build new legal_action_mask (or all-false if done)\n10. Return Ok(EnvStep{...})","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:16:22.786988+01:00","updated_at":"2025-12-10T17:40:50.276782+01:00","closed_at":"2025-12-10T17:40:50.276782+01:00","dependencies":[{"issue_id":"azul-85d.19","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:16:22.78757+01:00","created_by":"bkase"},{"issue_id":"azul-85d.19","depends_on_id":"azul-85d.18","type":"blocks","created_at":"2025-12-10T17:21:36.504462+01:00","created_by":"bkase"}]}
{"id":"azul-85d.2","title":"Implement RewardScheme enum","description":"Create RewardScheme enum with two variants:\n- `DenseScoreDelta`: reward[player] = score_after[player] - score_before[player] at every step, including final bonuses at terminal step\n- `TerminalOnly`: rewards are 0 until game over; at game over: reward[player] = final_score[player] - mean(final_scores)\nDerive Copy, Clone, Debug. Future extension: add Shaped reward scheme.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:13:18.873918+01:00","updated_at":"2025-12-10T17:39:17.284205+01:00","closed_at":"2025-12-10T17:39:17.284205+01:00","dependencies":[{"issue_id":"azul-85d.2","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:13:18.874507+01:00","created_by":"bkase"},{"issue_id":"azul-85d.2","depends_on_id":"azul-85d.33","type":"blocks","created_at":"2025-12-10T17:19:13.346876+01:00","created_by":"bkase"}]}
{"id":"azul-85d.20","title":"Implement DenseScoreDelta reward computation","description":"In Environment::step, for RewardScheme::DenseScoreDelta:\n```rust\nfor p in 0..num_players {\n    let new_score = game_state.players[p].score;\n    let delta = (new_score - prev_scores[p]) as f32;\n    rewards[p] = delta;\n}\n```\n- Computes incremental score change at every step\n- Includes all bonuses at terminal step (row/column/color completion)\n- Good for faster learning signal","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:16:29.744767+01:00","updated_at":"2025-12-10T17:41:05.496681+01:00","closed_at":"2025-12-10T17:41:05.496681+01:00","dependencies":[{"issue_id":"azul-85d.20","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:16:29.745301+01:00","created_by":"bkase"},{"issue_id":"azul-85d.20","depends_on_id":"azul-85d.19","type":"blocks","created_at":"2025-12-10T17:21:41.635812+01:00","created_by":"bkase"}]}
{"id":"azul-85d.21","title":"Implement TerminalOnly reward computation","description":"In Environment::step, for RewardScheme::TerminalOnly:\n```rust\nif phase == Phase::GameOver {\n    let final_scores: Vec\u003cf32\u003e = players.iter().map(|p| p.score as f32).collect();\n    let mean = final_scores.iter().sum::\u003cf32\u003e() / num_players as f32;\n    for p in 0..num_players {\n        rewards[p] = final_scores[p] - mean;\n    }\n} else {\n    // rewards remain [0.0; MAX_PLAYERS]\n}\n```\n- Zero reward until game ends\n- Final reward = player's score minus average score (zero-sum)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:16:36.114238+01:00","updated_at":"2025-12-10T17:41:10.560631+01:00","closed_at":"2025-12-10T17:41:10.560631+01:00","dependencies":[{"issue_id":"azul-85d.21","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:16:36.11478+01:00","created_by":"bkase"},{"issue_id":"azul-85d.21","depends_on_id":"azul-85d.19","type":"blocks","created_at":"2025-12-10T17:21:46.772657+01:00","created_by":"bkase"}]}
{"id":"azul-85d.22","title":"Implement AgentInput struct","description":"Create AgentInput struct for agent action selection:\n```rust\npub struct AgentInput\u003c'a\u003e {\n    pub observation: \u0026'a Observation,      // Obs for current player\n    pub legal_action_mask: \u0026'a [bool],     // mask[id]=true if legal\n    pub current_player: PlayerIdx,          // Whose turn it is\n}\n```\nLifetime 'a borrows from EnvStep to avoid unnecessary cloning.\nThis is the minimal input an agent needs to select an action.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:17:02.938952+01:00","updated_at":"2025-12-10T17:41:15.73132+01:00","closed_at":"2025-12-10T17:41:15.73132+01:00","dependencies":[{"issue_id":"azul-85d.22","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:17:02.939522+01:00","created_by":"bkase"},{"issue_id":"azul-85d.22","depends_on_id":"azul-85d.1","type":"blocks","created_at":"2025-12-10T17:21:54.25909+01:00","created_by":"bkase"}]}
{"id":"azul-85d.23","title":"Define Agent trait","description":"Create Agent trait for action selection:\n```rust\npub trait Agent {\n    fn select_action(\n        \u0026mut self, \n        input: \u0026AgentInput, \n        rng: \u0026mut impl Rng\n    ) -\u003e ActionId;\n}\n```\nRequirements:\n- Must only return ActionIds where legal_action_mask[id] == true\n- May use rng for exploration (epsilon-greedy, sampling, etc.)\n- Works for: random policy, neural net policy, MCTS, human input","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:17:09.185281+01:00","updated_at":"2025-12-10T17:41:20.801168+01:00","closed_at":"2025-12-10T17:41:20.801168+01:00","dependencies":[{"issue_id":"azul-85d.23","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:17:09.185875+01:00","created_by":"bkase"},{"issue_id":"azul-85d.23","depends_on_id":"azul-85d.22","type":"blocks","created_at":"2025-12-10T17:21:59.388045+01:00","created_by":"bkase"}]}
{"id":"azul-85d.24","title":"Implement RandomAgent","description":"Implement a simple RandomAgent for testing and baseline:\n```rust\npub struct RandomAgent;\n\nimpl Agent for RandomAgent {\n    fn select_action(\u0026mut self, input: \u0026AgentInput, rng: \u0026mut impl Rng) -\u003e ActionId {\n        let legal_ids: Vec\u003cActionId\u003e = input.legal_action_mask\n            .iter()\n            .enumerate()\n            .filter(|(_, \u0026legal)| legal)\n            .map(|(id, _)| id as ActionId)\n            .collect();\n        legal_ids[rng.gen_range(0..legal_ids.len())]\n    }\n}\n```\nUseful for smoke testing the environment loop.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T17:17:15.406609+01:00","updated_at":"2025-12-10T17:41:25.962864+01:00","closed_at":"2025-12-10T17:41:25.962864+01:00","dependencies":[{"issue_id":"azul-85d.24","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:17:15.408222+01:00","created_by":"bkase"},{"issue_id":"azul-85d.24","depends_on_id":"azul-85d.23","type":"blocks","created_at":"2025-12-10T17:22:04.524673+01:00","created_by":"bkase"}]}
{"id":"azul-85d.25","title":"Implement self_play_episode example function","description":"Implement reference self-play loop:\n```rust\npub fn self_play_episode\u003cF: FeatureExtractor, A: Agent\u003e(\n    env: \u0026mut AzulEnv\u003cF\u003e,\n    agent: \u0026mut A,\n    rng: \u0026mut impl Rng,\n    replay_buffer: \u0026mut Vec\u003cTransition\u003e,\n) {\n    let mut step = env.reset(rng);\n    while !step.done {\n        let p = step.current_player as usize;\n        let input = AgentInput { observation: \u0026step.observations[p], ... };\n        let action_id = agent.select_action(\u0026input, rng);\n        let next_step = env.step(action_id, rng).expect(\"step failed\");\n        replay_buffer.push(Transition { ... });\n        step = next_step;\n    }\n}\n```\nDemonstrates how to use the API for training data collection.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T17:17:22.473566+01:00","updated_at":"2025-12-10T17:45:25.918807+01:00","closed_at":"2025-12-10T17:45:25.918807+01:00","dependencies":[{"issue_id":"azul-85d.25","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:17:22.474086+01:00","created_by":"bkase"},{"issue_id":"azul-85d.25","depends_on_id":"azul-85d.24","type":"blocks","created_at":"2025-12-10T17:22:09.656884+01:00","created_by":"bkase"},{"issue_id":"azul-85d.25","depends_on_id":"azul-85d.19","type":"blocks","created_at":"2025-12-10T17:22:14.782959+01:00","created_by":"bkase"}]}
{"id":"azul-85d.26","title":"Implement legal action mask correctness tests","description":"Test legal_action_mask consistency with engine (Section 12.2):\nFor many random reachable GameStates:\n1. Compute legal = legal_actions(\u0026game_state)\n2. Compute mask = env.build_legal_action_mask()\n3. For each a in legal: id = encode(\u0026a) → assert mask[id] == true\n4. For each id with mask[id] == true: a = decode(id) → assert a is in legal\nThis ensures bijection between engine's legal_actions and mask's true entries.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:17:45.077218+01:00","updated_at":"2025-12-10T17:44:22.853926+01:00","closed_at":"2025-12-10T17:44:22.853926+01:00","dependencies":[{"issue_id":"azul-85d.26","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:17:45.077807+01:00","created_by":"bkase"},{"issue_id":"azul-85d.26","depends_on_id":"azul-85d.16","type":"blocks","created_at":"2025-12-10T17:22:32.210388+01:00","created_by":"bkase"}]}
{"id":"azul-85d.27","title":"Implement DenseScoreDelta reward correctness tests","description":"Test DenseScoreDelta reward scheme (Section 12.3):\nRun full random episodes:\n1. Track per-player cumulative reward: cum_reward[p] = Σ_t reward_t[p]\n2. At end, check: cum_reward[p] == final_score[p] - initial_score[p]\n   (initial_score is always 0)\n3. Verify step rewards match engine scoring exactly\nThis ensures our incremental rewards sum to final scores.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:17:51.02908+01:00","updated_at":"2025-12-10T17:44:28.019181+01:00","closed_at":"2025-12-10T17:44:28.019181+01:00","dependencies":[{"issue_id":"azul-85d.27","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:17:51.029611+01:00","created_by":"bkase"},{"issue_id":"azul-85d.27","depends_on_id":"azul-85d.20","type":"blocks","created_at":"2025-12-10T17:22:37.337493+01:00","created_by":"bkase"}]}
{"id":"azul-85d.28","title":"Implement TerminalOnly reward correctness tests","description":"Test TerminalOnly reward scheme (Section 12.3):\n1. Verify reward_t[p] == 0 for all non-terminal steps\n2. At terminal step:\n   - Σ_p reward_terminal[p] == 0 (zero-sum property)\n   - reward_terminal[p] == final_score[p] - mean(final_scores)\n3. Run multiple episodes to verify consistency","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:17:56.95433+01:00","updated_at":"2025-12-10T17:44:33.190762+01:00","closed_at":"2025-12-10T17:44:33.190762+01:00","dependencies":[{"issue_id":"azul-85d.28","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:17:56.954895+01:00","created_by":"bkase"},{"issue_id":"azul-85d.28","depends_on_id":"azul-85d.21","type":"blocks","created_at":"2025-12-10T17:22:42.467671+01:00","created_by":"bkase"}]}
{"id":"azul-85d.29","title":"Implement environment determinism tests","description":"Test determinism (Section 12.4):\nWith fixed RNG seed and fixed sequence of ActionIds:\n1. Run env.reset() + repeated env.step(action_id) twice with same seed\n2. Assert EnvStep.state (if included) identical across runs\n3. Assert observations identical across runs\n4. Assert rewards identical across runs\n5. Assert legal_action_masks identical\nThis ensures environment is pure given (seed, actions).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:18:05.015041+01:00","updated_at":"2025-12-10T17:44:38.339168+01:00","closed_at":"2025-12-10T17:44:38.339168+01:00","dependencies":[{"issue_id":"azul-85d.29","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:18:05.015566+01:00","created_by":"bkase"},{"issue_id":"azul-85d.29","depends_on_id":"azul-85d.19","type":"blocks","created_at":"2025-12-10T17:22:47.598069+01:00","created_by":"bkase"}]}
{"id":"azul-85d.3","title":"Implement EnvConfig struct","description":"Create EnvConfig struct with fields:\n- `num_players: u8` (2..=4, must match GameState.num_players)\n- `reward_scheme: RewardScheme` (reward computation strategy)\n- `include_full_state_in_step: bool` (if true, EnvStep.state contains full GameState clone for debugging)\nDerive Clone, Debug.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:13:25.468129+01:00","updated_at":"2025-12-10T17:39:22.447482+01:00","closed_at":"2025-12-10T17:39:22.447482+01:00","dependencies":[{"issue_id":"azul-85d.3","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:13:25.468666+01:00","created_by":"bkase"},{"issue_id":"azul-85d.3","depends_on_id":"azul-85d.2","type":"blocks","created_at":"2025-12-10T17:19:18.475111+01:00","created_by":"bkase"}]}
{"id":"azul-85d.30","title":"Implement illegal action handling tests","description":"Test illegal action handling (Section 12.6):\n1. Pick random states and random ActionIds\n2. If mask[id] == false, then env.step(id, rng) must return Err(StepError::IllegalAction(id))\n3. Confirm EpisodeDone is returned for step() calls after done == true\n4. Test edge cases: ActionId at boundary (299), invalid ActionId (\u003e= 300)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:18:27.499946+01:00","updated_at":"2025-12-10T17:44:43.495726+01:00","closed_at":"2025-12-10T17:44:43.495726+01:00","dependencies":[{"issue_id":"azul-85d.30","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:18:27.500489+01:00","created_by":"bkase"},{"issue_id":"azul-85d.30","depends_on_id":"azul-85d.19","type":"blocks","created_at":"2025-12-10T17:22:52.728173+01:00","created_by":"bkase"}]}
{"id":"azul-85d.31","title":"Implement integration smoke test","description":"Full integration test:\n1. Create AzulEnv with BasicFeatureExtractor and EnvConfig\n2. Run 100 complete random episodes with RandomAgent\n3. Verify no panics, all episodes terminate with done=true\n4. Verify observations are valid (correct shape, dtype)\n5. Verify rewards accumulate correctly\n6. Collect basic statistics: avg game length, avg final scores\nThis is the smoke test that ensures all components work together.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:18:35.293697+01:00","updated_at":"2025-12-10T17:44:48.65385+01:00","closed_at":"2025-12-10T17:44:48.65385+01:00","dependencies":[{"issue_id":"azul-85d.31","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:18:35.294235+01:00","created_by":"bkase"},{"issue_id":"azul-85d.31","depends_on_id":"azul-85d.24","type":"blocks","created_at":"2025-12-10T17:22:59.733068+01:00","created_by":"bkase"},{"issue_id":"azul-85d.31","depends_on_id":"azul-85d.19","type":"blocks","created_at":"2025-12-10T17:23:04.856329+01:00","created_by":"bkase"},{"issue_id":"azul-85d.31","depends_on_id":"azul-85d.12","type":"blocks","created_at":"2025-12-10T17:23:09.992889+01:00","created_by":"bkase"}]}
{"id":"azul-85d.32","title":"Define Transition struct for replay buffer","description":"Create Transition struct for storing experience:\n```rust\npub struct Transition {\n    pub player: PlayerIdx,\n    pub observation_before: Observation,\n    pub action_id: ActionId,\n    pub reward: Reward,\n    pub observation_after: Observation,\n    pub done: bool,\n}\n```\nUsed by self_play_episode to collect training data.\nClone-able for replay buffer storage.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T17:18:41.36019+01:00","updated_at":"2025-12-10T17:41:31.11899+01:00","closed_at":"2025-12-10T17:41:31.11899+01:00","dependencies":[{"issue_id":"azul-85d.32","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:18:41.36076+01:00","created_by":"bkase"},{"issue_id":"azul-85d.32","depends_on_id":"azul-85d.1","type":"blocks","created_at":"2025-12-10T17:22:19.915854+01:00","created_by":"bkase"}]}
{"id":"azul-85d.33","title":"Set up rl_env module structure","description":"Create module structure for RL environment code:\n1. Create src/rl_env/mod.rs with public re-exports\n2. Create src/rl_env/types.rs for ActionId, Reward, Observation, RewardScheme, EnvConfig\n3. Create src/rl_env/action_encoder.rs for ActionEncoder\n4. Create src/rl_env/feature_extractor.rs for FeatureExtractor trait + BasicFeatureExtractor\n5. Create src/rl_env/environment.rs for Environment trait + AzulEnv\n6. Create src/rl_env/agent.rs for AgentInput, Agent trait, RandomAgent\n7. Update src/lib.rs to include pub mod rl_env\nThis establishes clean code organization before implementation.","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-10T17:18:47.327852+01:00","updated_at":"2025-12-10T17:39:06.953982+01:00","closed_at":"2025-12-10T17:39:06.953982+01:00","dependencies":[{"issue_id":"azul-85d.33","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:18:47.328448+01:00","created_by":"bkase"}]}
{"id":"azul-85d.4","title":"Implement StepError enum","description":"Create StepError enum with variants:\n- `EpisodeDone`: step() called after episode has already terminated\n- `InvalidActionId(ActionId)`: ActionId could not be decoded into syntactically valid Action\n- `IllegalAction(ActionId)`: ActionId decodes to Action which is illegal in current state\nDerive Debug. Used as error type for Environment::step().","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:13:31.527621+01:00","updated_at":"2025-12-10T17:39:27.607504+01:00","closed_at":"2025-12-10T17:39:27.607504+01:00","dependencies":[{"issue_id":"azul-85d.4","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:13:31.528165+01:00","created_by":"bkase"},{"issue_id":"azul-85d.4","depends_on_id":"azul-85d.1","type":"blocks","created_at":"2025-12-10T17:19:23.60273+01:00","created_by":"bkase"}]}
{"id":"azul-85d.5","title":"Implement EnvStep struct","description":"Create EnvStep\u003cO, R\u003e struct with fields:\n- `observations: [O; MAX_PLAYERS]` - observation per player from that player's perspective\n- `rewards: [R; MAX_PLAYERS]` - reward per player for most recent transition (zeros on reset)\n- `done: bool` - true if episode has terminated\n- `current_player: PlayerIdx` - player whose turn it is after this step\n- `legal_action_mask: Vec\u003cbool\u003e` - mask[id]=true if ActionId legal for current_player\n- `last_action: Option\u003cActionId\u003e` - last action taken (None on reset)\n- `state: Option\u003cGameState\u003e` - optional full state for debugging","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:13:38.379934+01:00","updated_at":"2025-12-10T17:39:32.684215+01:00","closed_at":"2025-12-10T17:39:32.684215+01:00","dependencies":[{"issue_id":"azul-85d.5","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:13:38.380438+01:00","created_by":"bkase"},{"issue_id":"azul-85d.5","depends_on_id":"azul-85d.1","type":"blocks","created_at":"2025-12-10T17:19:28.724042+01:00","created_by":"bkase"}]}
{"id":"azul-85d.6","title":"Define ACTION_SPACE_SIZE and encoding constants","description":"Define action encoding constants:\n- `pub const ACTION_SPACE_SIZE: usize = 300;`\nEncoding formula: id = ((((s_type * MAX_FACTORIES + s_idx) * TILE_COLORS + c_idx) * 2 + d_type) * BOARD_SIZE + d_idx)\nWhere: s_type∈{0,1} (Factory/Center), s_idx∈0..9, c_idx∈0..5, d_type∈{0,1} (PatternLine/Floor), d_idx∈0..5\nResult: (9+1) * 5 * 2 * 5 = 300 total action IDs covering all syntactically possible draft moves.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:14:03.596631+01:00","updated_at":"2025-12-10T17:39:45.86349+01:00","closed_at":"2025-12-10T17:39:45.86349+01:00","dependencies":[{"issue_id":"azul-85d.6","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:14:03.597169+01:00","created_by":"bkase"},{"issue_id":"azul-85d.6","depends_on_id":"azul-85d.1","type":"blocks","created_at":"2025-12-10T17:19:35.982726+01:00","created_by":"bkase"}]}
{"id":"azul-85d.7","title":"Implement ActionEncoder::encode","description":"Implement ActionEncoder::encode(\u0026Action) -\u003e ActionId method:\n1. Extract s_type (0=Factory, 1=Center) and s_idx from action.source\n2. Extract c_idx from action.color as u16\n3. Extract d_type (0=PatternLine, 1=Floor) and d_idx from action.dest\n4. Pack: id = ((((s_type * MAX_FACTORIES + s_idx) * TILE_COLORS + c_idx) * 2 + d_type) * BOARD_SIZE + d_idx)\n5. debug_assert!(id \u003c ACTION_SPACE_SIZE)\nReturn ActionId. Panics in debug if indices out of range.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:14:10.447551+01:00","updated_at":"2025-12-10T17:39:50.918528+01:00","closed_at":"2025-12-10T17:39:50.918528+01:00","dependencies":[{"issue_id":"azul-85d.7","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:14:10.448138+01:00","created_by":"bkase"},{"issue_id":"azul-85d.7","depends_on_id":"azul-85d.6","type":"blocks","created_at":"2025-12-10T17:19:41.104027+01:00","created_by":"bkase"}]}
{"id":"azul-85d.8","title":"Implement ActionEncoder::decode","description":"Implement ActionEncoder::decode(ActionId) -\u003e Action method:\n1. assert!(id \u003c ACTION_SPACE_SIZE)\n2. Unpack in reverse order: d_idx = x % BOARD_SIZE; x /= BOARD_SIZE; d_type = x % 2; x /= 2; etc.\n3. Reconstruct DraftSource from s_type/s_idx (0=Factory(s_idx), 1=Center)\n4. Reconstruct Color using Color::from_index(c_idx) \n5. Reconstruct DraftDestination from d_type/d_idx (0=PatternLine(d_idx), 1=Floor)\nReturn Action. May produce syntactically valid but illegal actions - env must mask.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T17:14:16.886692+01:00","updated_at":"2025-12-10T17:39:55.973688+01:00","closed_at":"2025-12-10T17:39:55.973688+01:00","dependencies":[{"issue_id":"azul-85d.8","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:14:16.887338+01:00","created_by":"bkase"},{"issue_id":"azul-85d.8","depends_on_id":"azul-85d.6","type":"blocks","created_at":"2025-12-10T17:19:46.227603+01:00","created_by":"bkase"}]}
{"id":"azul-85d.9","title":"Implement ActionEncoder unit tests","description":"Property-based tests for ActionEncoder:\n1. Round-trip test: For random valid Actions, assert decode(encode(a)) == a\n2. Decode bounds test: For all id in 0..ACTION_SPACE_SIZE, decode(id) produces Action with valid field ranges\n3. Encode produces valid range: For all valid Actions, encode(a) \u003c ACTION_SPACE_SIZE\n4. Edge cases: Test boundary conditions (factory 0, factory 8, center, all colors, all pattern lines, floor)\nUse proptest or quickcheck for randomized coverage.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T17:14:24.64598+01:00","updated_at":"2025-12-10T17:45:36.219321+01:00","closed_at":"2025-12-10T17:45:36.219321+01:00","dependencies":[{"issue_id":"azul-85d.9","depends_on_id":"azul-85d","type":"parent-child","created_at":"2025-12-10T17:14:24.646584+01:00","created_by":"bkase"},{"issue_id":"azul-85d.9","depends_on_id":"azul-85d.7","type":"blocks","created_at":"2025-12-10T17:19:51.361506+01:00","created_by":"bkase"},{"issue_id":"azul-85d.9","depends_on_id":"azul-85d.8","type":"blocks","created_at":"2025-12-10T17:19:56.489928+01:00","created_by":"bkase"}]}
{"id":"azul-9sh","title":"Game Spec \u0026 Design","description":"Formalize Azul game rules, state representation, action space, and victory conditions","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-09T21:14:27.05717+01:00","updated_at":"2025-12-09T21:14:27.05717+01:00","labels":["design","spec"]}
{"id":"azul-a3i","title":"Switch inference worker to drain-loop on bounded channel","description":"Replace the current inference worker coalescing logic (spin window + try_recv) with a single-consumer drain loop on a bounded channel:\n\nPlan:\n- Use a bounded channel (capacity ~1024) to provide natural backpressure and batch formation.\n- Worker loop: block on recv for the first request, then immediately drain as many pending requests as possible (up to max_batch = 4 * nn_batch_size) before dispatching one predict_batch.\n- Optional: if the first batch is small (\u003c min_batch_to_dispatch, e.g., nn_batch_size/2) and the queue is empty, sleep 50–100µs once to allow more arrivals; otherwise dispatch immediately.\n- Preserve per-request shape safety: only coalesce when obs_size matches; otherwise flush mismatched shapes separately.\n- Maintain profiling counters: nn_batches, nn_positions, nn_evals, time_nn_worker_ns, time_nn_worker_queue_ns with the new loop (queue time = wait+drain+slice; worker time = predict_batch).\n- Goals: reduce NN worker queue time (currently ~0.73s/iter) and batch count (~2500) while keeping compute time low and wall iter ~1s.\n- Validate with \nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 3 tests\ntest tests::test_parse_iteration_from_checkpoint_invalid ... ok\ntest tests::test_parse_iteration_from_checkpoint_valid ... ok\ntest tests::test_parse_iteration_handles_large_numbers ... ok\n\ntest result: ok. 3 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 37 tests\ntest tests::test_apply_action_basic ... ok\ntest tests::test_apply_action_illegal ... ok\ntest tests::test_apply_action_wrong_phase ... ok\ntest tests::test_deterministic_new_game ... ok\ntest tests::test_deterministic_replay ... ok\ntest tests::test_endgame_bonus_combined ... ok\ntest tests::test_endgame_bonus_complete_color ... ok\ntest tests::test_endgame_bonus_horizontal_row ... ok\ntest tests::test_endgame_bonus_vertical_column ... ok\ntest tests::test_factory_refill_from_discard ... ok\ntest tests::test_factory_refill_partial_when_empty ... ok\ntest tests::test_first_player_marker_determines_next_starter ... ok\ntest tests::test_first_player_marker_starts_in_center ... ok\ntest tests::test_first_player_marker_taken_on_center_pick ... ok\ntest tests::test_floor_partial_penalties ... ok\ntest tests::test_floor_penalty_calculation ... ok\ntest tests::test_floor_penalty_score_clamp ... ok\ntest tests::test_full_game_3_players ... ok\ntest tests::test_full_game_4_players ... ok\ntest tests::test_full_game_simulation ... ok\ntest tests::test_legal_actions_floor_always_available ... ok\ntest tests::test_legal_actions_full_pattern_line ... ok\ntest tests::test_legal_actions_non_empty ... ok\ntest tests::test_legal_actions_pattern_line_homogeneity ... ok\ntest tests::test_legal_actions_wall_constraint ... ok\ntest tests::test_new_game_3_players ... ok\ntest tests::test_new_game_4_players ... ok\ntest tests::test_new_game_creates_valid_state ... ok\ntest tests::test_pattern_line_invariants ... ok\ntest tests::test_score_placement_corner ... ok\ntest tests::test_score_placement_cross ... ok\ntest tests::test_score_placement_edge_horizontal ... ok\ntest tests::test_score_placement_horizontal ... ok\ntest tests::test_score_placement_isolated ... ok\ntest tests::test_score_placement_vertical ... ok\ntest tests::test_tile_invariants_throughout_game ... ok\ntest tests::test_wall_positions_match_pattern ... ok\n\ntest result: ok. 37 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.01s\n\n\nrunning 66 tests\ntest action_encoder::tests::test_action_space_size_calculation ... ok\ntest action_encoder::tests::test_decode_all_valid_ids ... ok\ntest action_encoder::tests::test_round_trip_all_factories ... ok\ntest action_encoder::tests::test_round_trip_center ... ok\ntest action_encoder::tests::test_round_trip_center_floor ... ok\ntest action_encoder::tests::test_round_trip_factory_pattern_line ... ok\ntest agent::tests::test_random_agent_many_selections ... ok\ntest agent::tests::test_random_agent_selects_legal_action ... ok\ntest alphazero::replay_buffer::tests::test_replay_buffer_extend ... ok\ntest alphazero::replay_buffer::tests::test_replay_buffer_overwrite_oldest ... ok\ntest alphazero::replay_buffer::tests::test_replay_buffer_push_and_len ... ok\ntest alphazero::replay_buffer::tests::test_replay_buffer_sample_empty_panics - should panic ... ok\ntest alphazero::replay_buffer::tests::test_replay_buffer_sample_returns_valid_refs ... ok\ntest alphazero::training::tests::test_build_training_batch_shapes ... ok\ntest alphazero::training::tests::test_compute_outcomes_clamps_extreme_values ... ok\ntest alphazero::training::tests::test_compute_outcomes_from_scores_zero_sum ... ok\ntest alphazero::training::tests::test_compute_outcomes_multi_player_tie ... ok\ntest alphazero::training::tests::test_cross_entropy_loss_one_hot ... ok\ntest alphazero::training::tests::test_loss_fn_runs_on_toy_batch ... ok\ntest alphazero::training::tests::test_mse_loss ... ok\ntest alphazero::training::tests::test_sanity_can_overfit_single_batch ... ok\ntest alphazero::training::tests::test_self_play_determinism_with_stub_model ... ok\ntest alphazero::training::tests::test_self_play_episode_runtime ... ok\ntest alphazero::training::tests::test_self_play_generates_examples ... ok\ntest alphazero::training::tests::test_self_play_respects_max_moves ... ok\ntest alphazero::training::tests::test_trainer_respects_start_iter ... ok\ntest alphazero::training::tests::test_trainer_runs_small_config ... ok\ntest alphazero::training::tests::test_trainer_skips_all_when_start_equals_num_iters ... ok\ntest alphazero_net::tests::test_alphazero_net_batch ... ok\ntest alphazero_net::tests::test_alphazero_net_determinism ... ok\ntest alphazero_net::tests::test_alphazero_net_shapes ... ok\ntest alphazero_net::tests::test_apply_gradients_changes_model ... ok\ntest alphazero_net::tests::test_eval_parameters_does_not_panic ... ok\ntest alphazero_net::tests::test_module_parameters_returns_real_weights ... ok\ntest alphazero_net::tests::test_param_count_matches_actual_parameters ... ok\ntest alphazero_net::tests::test_save_load_safetensors_roundtrip ... ok\ntest environment::tests::test_azul_env_episode_done_error ... ok\ntest environment::tests::test_azul_env_illegal_action_error ... ok\ntest environment::tests::test_azul_env_new ... ok\ntest environment::tests::test_azul_env_reset ... ok\ntest environment::tests::test_azul_env_step ... ok\ntest environment::tests::test_dense_score_delta_reward_correctness ... ok\ntest environment::tests::test_environment_determinism ... ok\ntest environment::tests::test_integration_smoke_100_episodes ... ok\ntest environment::tests::test_legal_action_mask_consistency ... ok\ntest environment::tests::test_terminal_only_reward_correctness ... ok\ntest feature_extractor::tests::test_basic_extractor_determinism ... ok\ntest feature_extractor::tests::test_basic_extractor_encode ... ok\ntest feature_extractor::tests::test_basic_extractor_obs_size ... ok\ntest feature_extractor::tests::test_create_zero_observation ... ok\ntest feature_extractor::tests::test_different_player_perspectives ... ok\ntest mcts::tests::test_agent_input_state_is_some ... ok\ntest mcts::tests::test_apply_temperature_argmax ... ok\ntest mcts::tests::test_apply_temperature_uniform ... ok\ntest mcts::tests::test_backup_flips_value_when_to_play_changes ... ok\ntest mcts::tests::test_backup_keeps_value_when_to_play_same ... ok\ntest mcts::tests::test_batched_mcts_invariants ... ok\ntest mcts::tests::test_mcts_agent_selects_legal_action ... ok\ntest mcts::tests::test_mcts_config_default ... ok\ntest mcts::tests::test_mcts_determinism ... ok\ntest mcts::tests::test_mcts_full_game_smoke ... ok\ntest mcts::tests::test_mcts_never_selects_illegal_action ... ok\ntest mcts::tests::test_mcts_prefers_higher_dense_reward_in_terminal_puzzle ... ok\ntest mcts::tests::test_sample_from_policy_argmax ... ok\ntest mcts::tests::test_softmax_basic ... ok\ntest mcts::tests::test_softmax_empty ... ok\n\ntest result: ok. 66 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 1.11s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s\n\n\nrunning 0 tests\n\ntest result: ok. 0 passed; 0 failed; 0 ignored; 0 measured; 0 filtered out; finished in 0.00s and the profiling run command; report new batch size/queue time.\n","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-14T22:25:28.94702Z","updated_at":"2025-12-14T22:25:28.94702Z","dependencies":[{"issue_id":"azul-a3i","depends_on_id":"azul-pdt.1","type":"discovered-from","created_at":"2025-12-14T22:25:28.949318Z","created_by":"bkase"}]}
{"id":"azul-ajf","title":"Milestone 5: External Profiling \u0026 Flamegraphs","description":"Document and execute external profiling workflow using cargo flamegraph and OS profilers to validate instrumentation findings and discover unexpected hotspots.","status":"closed","priority":3,"issue_type":"epic","created_at":"2025-12-11T00:50:59.534221+01:00","updated_at":"2025-12-13T16:57:30.263889+01:00","closed_at":"2025-12-13T16:57:30.263889+01:00","dependencies":[{"issue_id":"azul-ajf","depends_on_id":"azul-nf5","type":"blocks","created_at":"2025-12-11T00:56:24.810898+01:00","created_by":"bkase"}]}
{"id":"azul-ajf.1","title":"Create docs/PROFILING.md","description":"Document standard profiling workflow: (1) Build with profiling feature: cargo build --release --features profiling. (2) cargo flamegraph usage with recommended small hyperparameters (--num-iters 2 --games-per-iter 1 --training-steps 5 --mcts-sims 20). (3) Note macOS Instruments as alternative. Include how to interpret results.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T00:55:36.269159+01:00","updated_at":"2025-12-11T01:53:49.254099+01:00","closed_at":"2025-12-11T01:53:49.254099+01:00","dependencies":[{"issue_id":"azul-ajf.1","depends_on_id":"azul-ajf","type":"parent-child","created_at":"2025-12-11T00:55:36.269727+01:00","created_by":"bkase"}]}
{"id":"azul-ajf.2","title":"Run cargo flamegraph analysis","description":"Execute cargo flamegraph with realistic small workloads. Verify expected hotspots (MCTS, feature extraction, NN forward, FD training) match counter instrumentation. Look for unexpected 'mystery' hotspots (allocator, logging, MLX internals). Document findings in history/flamegraph_analysis.md.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T00:55:43.197465+01:00","updated_at":"2025-12-13T16:57:23.457161+01:00","closed_at":"2025-12-13T16:57:23.457161+01:00","dependencies":[{"issue_id":"azul-ajf.2","depends_on_id":"azul-ajf","type":"parent-child","created_at":"2025-12-11T00:55:43.19803+01:00","created_by":"bkase"},{"issue_id":"azul-ajf.2","depends_on_id":"azul-ajf.1","type":"blocks","created_at":"2025-12-11T00:59:45.688215+01:00","created_by":"bkase"},{"issue_id":"azul-ajf.2","depends_on_id":"azul-ajf.3","type":"blocks","created_at":"2025-12-11T00:59:51.903086+01:00","created_by":"bkase"}]}
{"id":"azul-ajf.3","title":"Install cargo-flamegraph if needed","description":"Ensure cargo-flamegraph is installed (cargo install flamegraph). On macOS, may need to configure dtrace permissions or use Instruments as alternative. Document any platform-specific setup requirements.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T00:55:50.25734+01:00","updated_at":"2025-12-11T01:52:58.621055+01:00","closed_at":"2025-12-11T01:52:58.621055+01:00","dependencies":[{"issue_id":"azul-ajf.3","depends_on_id":"azul-ajf","type":"parent-child","created_at":"2025-12-11T00:55:50.257817+01:00","created_by":"bkase"}]}
{"id":"azul-ctu","title":"Use clap for CLI argument parsing","description":"Replace manual arg parsing in main.rs with clap derive macros for cleaner CLI with automatic help generation, validation, and better error messages.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T00:39:06.120341+01:00","updated_at":"2025-12-11T01:15:06.982892+01:00","closed_at":"2025-12-11T01:15:06.982892+01:00"}
{"id":"azul-d2z","title":"AlphaZero MCTS Agent Implementation","description":"Implement AlphaZero-style MCTS agent with neural network policy/value function using mlx-rs. Integrates with existing azul-engine and azul-rl-env. Initial focus on 2-player games with TerminalOnly reward scheme.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-10T22:04:40.378316+01:00","updated_at":"2025-12-10T22:35:30.912172+01:00","closed_at":"2025-12-10T22:35:30.912172+01:00"}
{"id":"azul-d2z.1","title":"Extend AgentInput with GameState","description":"Add 'state: Option\u003c\u0026GameState\u003e' field to AgentInput struct. MCTS needs full GameState to roll out future states. Update struct definition in crates/rl-env/src/agent.rs. This is a breaking change that requires updating all AgentInput constructors.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:04:57.903089+01:00","updated_at":"2025-12-10T22:22:25.953796+01:00","closed_at":"2025-12-10T22:22:25.953796+01:00","dependencies":[{"issue_id":"azul-d2z.1","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:04:57.90368+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.10","title":"Add rand_distr dependency for Dirichlet noise","description":"Add rand_distr = \"0.4\" (or matching rand minor version) to azul-rl-env Cargo.toml. Required for root Dirichlet noise implementation using rand_distr::Dirichlet.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:06:26.314268+01:00","updated_at":"2025-12-10T22:23:52.738846+01:00","closed_at":"2025-12-10T22:23:52.738846+01:00","dependencies":[{"issue_id":"azul-d2z.10","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:06:26.314779+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.11","title":"Implement root Dirichlet noise","description":"Implement add_dirichlet_noise(edges: \u0026mut [ChildEdge], alpha: f32, eps: f32, rng: \u0026mut impl Rng). Sample eta ~ Dir(alpha) over root edges. Update priors: P'(s0,a) = (1-eps)*P(s0,a) + eps*eta_a. Skip if alpha \u003c= 0. Called once per root for self-play exploration.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:06:35.248958+01:00","updated_at":"2025-12-10T22:30:16.206112+01:00","closed_at":"2025-12-10T22:30:16.206112+01:00","dependencies":[{"issue_id":"azul-d2z.11","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:06:35.249717+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.11","depends_on_id":"azul-d2z.10","type":"blocks","created_at":"2025-12-10T22:12:23.825303+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.12","title":"Implement PUCT selection (select_child)","description":"Implement select_child(\u0026self, node: \u0026Node) -\u003e usize. PUCT formula: Q(s,a) = W(s,a)/N(s,a) if N\u003e0 else 0. U(s,a) = cpuct * P(s,a) * sqrt(N+1)/(1+N(s,a)). Select argmax(Q+U). Returns index into node.children vec. Used during tree traversal.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:07:01.516149+01:00","updated_at":"2025-12-10T22:30:21.3044+01:00","closed_at":"2025-12-10T22:30:21.3044+01:00","dependencies":[{"issue_id":"azul-d2z.12","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:07:01.516722+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.12","depends_on_id":"azul-d2z.6","type":"blocks","created_at":"2025-12-10T22:12:54.002244+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.13","title":"Implement expansion and evaluation","description":"At leaf node: (1) Check terminal - if GameOver, compute value from scores. (2) Non-terminal: encode state via FeatureExtractor, call PolicyValueNet::predict_single, get legal_actions from engine, compute softmax over legal logits to get priors, create ChildEdge for each legal action, return leaf_value from network.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:07:07.812533+01:00","updated_at":"2025-12-10T22:30:26.4173+01:00","closed_at":"2025-12-10T22:30:26.4173+01:00","dependencies":[{"issue_id":"azul-d2z.13","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:07:07.813278+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.13","depends_on_id":"azul-d2z.6","type":"blocks","created_at":"2025-12-10T22:12:59.138114+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.13","depends_on_id":"azul-d2z.4","type":"blocks","created_at":"2025-12-10T22:13:04.27359+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.13","depends_on_id":"azul-d2z.7","type":"blocks","created_at":"2025-12-10T22:13:09.405977+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.14","title":"Implement backup (value propagation)","description":"Implement backup(\u0026mut self, path: \u0026[PathStep], leaf_value: f32). PathStep has node_idx, child_idx, to_play. Traverse path in reverse, update edge.visit_count += 1, edge.value_sum += value, node.visit_count += 1, then flip value = -value for 2-player zero-sum. Assert num_players == 2.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:07:14.267507+01:00","updated_at":"2025-12-10T22:30:31.535029+01:00","closed_at":"2025-12-10T22:30:31.535029+01:00","dependencies":[{"issue_id":"azul-d2z.14","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:07:14.268034+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.14","depends_on_id":"azul-d2z.6","type":"blocks","created_at":"2025-12-10T22:13:14.538605+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.15","title":"Implement run_search main MCTS loop","description":"Implement run_search(\u0026mut self, root_state: \u0026GameState, rng: \u0026mut impl Rng) -\u003e [f32; ACTION_SPACE_SIZE]. Loop num_simulations times: selection (traverse tree via PUCT), expansion at leaf, backup. Add root Dirichlet noise once. After simulations, extract visit counts from root children and apply temperature to get policy pi.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:07:21.271983+01:00","updated_at":"2025-12-10T22:30:36.64732+01:00","closed_at":"2025-12-10T22:30:36.64732+01:00","dependencies":[{"issue_id":"azul-d2z.15","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:07:21.27246+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.15","depends_on_id":"azul-d2z.12","type":"blocks","created_at":"2025-12-10T22:13:21.184382+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.15","depends_on_id":"azul-d2z.13","type":"blocks","created_at":"2025-12-10T22:13:26.320747+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.15","depends_on_id":"azul-d2z.14","type":"blocks","created_at":"2025-12-10T22:13:31.449976+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.15","depends_on_id":"azul-d2z.8","type":"blocks","created_at":"2025-12-10T22:13:36.576402+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.15","depends_on_id":"azul-d2z.11","type":"blocks","created_at":"2025-12-10T22:13:41.704062+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.16","title":"Implement AlphaZeroMctsAgent struct","description":"Create AlphaZeroMctsAgent\u003cF: FeatureExtractor, N: PolicyValueNet\u003e with fields: config: MctsConfig, features: F, net: N. Implement new(config, features, net) constructor. This struct orchestrates MCTS search using the feature extractor and neural network.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:07:27.288805+01:00","updated_at":"2025-12-10T22:30:51.899889+01:00","closed_at":"2025-12-10T22:30:51.899889+01:00","dependencies":[{"issue_id":"azul-d2z.16","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:07:27.289335+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.16","depends_on_id":"azul-d2z.4","type":"blocks","created_at":"2025-12-10T22:13:48.758709+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.16","depends_on_id":"azul-d2z.5","type":"blocks","created_at":"2025-12-10T22:13:53.894203+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.17","title":"Implement Agent trait for AlphaZeroMctsAgent","description":"Impl Agent for AlphaZeroMctsAgent. In select_action: assert state.is_some() and num_players==2, call run_search to get pi, apply legal_action_mask, renormalize, sample final action via sample_from_policy. Return ActionId.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:07:33.329782+01:00","updated_at":"2025-12-10T22:30:57.020458+01:00","closed_at":"2025-12-10T22:30:57.020458+01:00","dependencies":[{"issue_id":"azul-d2z.17","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:07:33.3303+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.17","depends_on_id":"azul-d2z.15","type":"blocks","created_at":"2025-12-10T22:13:59.02167+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.17","depends_on_id":"azul-d2z.16","type":"blocks","created_at":"2025-12-10T22:14:04.148591+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.17","depends_on_id":"azul-d2z.9","type":"blocks","created_at":"2025-12-10T22:14:09.277229+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.18","title":"Create alphazero_net.rs module file","description":"Create new file crates/rl-env/src/alphazero_net.rs. This module will contain the AlphaZeroNet struct implementing a simple fully-connected architecture using mlx_rs::nn primitives (Linear, Relu, Tanh, Sequential).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:07:55.656413+01:00","updated_at":"2025-12-10T22:29:03.703785+01:00","closed_at":"2025-12-10T22:29:03.703785+01:00","dependencies":[{"issue_id":"azul-d2z.18","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:07:55.65697+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.19","title":"Define AlphaZeroNet struct","description":"Create AlphaZeroNet struct with fields: obs_size: usize, hidden_size: usize, trunk: Sequential (shared layers), policy_head: Sequential (outputs [ACTION_SPACE_SIZE] logits), value_head: Sequential (outputs scalar in [-1,1] via Tanh).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:08:02.535223+01:00","updated_at":"2025-12-10T22:31:02.136354+01:00","closed_at":"2025-12-10T22:31:02.136354+01:00","dependencies":[{"issue_id":"azul-d2z.19","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:08:02.535693+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.19","depends_on_id":"azul-d2z.18","type":"blocks","created_at":"2025-12-10T22:14:23.29306+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.2","title":"Update self_play_episode to pass state to AgentInput","description":"In environment.rs self_play_episode function, update AgentInput construction to pass 'state: step.state.as_ref()'. Requires EnvConfig.include_full_state_in_step == true for MCTS usage.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:05:05.155751+01:00","updated_at":"2025-12-10T22:22:31.071721+01:00","closed_at":"2025-12-10T22:22:31.071721+01:00","dependencies":[{"issue_id":"azul-d2z.2","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:05:05.156363+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.2","depends_on_id":"azul-d2z.1","type":"blocks","created_at":"2025-12-10T22:11:32.977456+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.20","title":"Implement AlphaZeroNet::new constructor","description":"Implement new(obs_size, hidden_size) -\u003e Self. Build trunk: Linear(obs_size, hidden_size) -\u003e Relu -\u003e Linear(hidden_size, hidden_size) -\u003e Relu. Policy head: Linear(hidden_size, hidden_size) -\u003e Relu -\u003e Linear(hidden_size, ACTION_SPACE_SIZE). Value head: Linear(hidden_size, hidden_size) -\u003e Relu -\u003e Linear(hidden_size, 1) -\u003e Tanh.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:08:08.544536+01:00","updated_at":"2025-12-10T22:31:07.253617+01:00","closed_at":"2025-12-10T22:31:07.253617+01:00","dependencies":[{"issue_id":"azul-d2z.20","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:08:08.545019+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.20","depends_on_id":"azul-d2z.19","type":"blocks","created_at":"2025-12-10T22:14:28.427915+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.21","title":"Implement AlphaZeroNet::forward_batch","description":"Implement forward_batch(\u0026self, obs_batch: \u0026Array) -\u003e (Array, Array). obs_batch shape [B, obs_size]. Run through trunk, then policy_head and value_head separately. Return (policy_logits [B, ACTION_SPACE_SIZE], values [B]).","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:08:14.728177+01:00","updated_at":"2025-12-10T22:31:12.370724+01:00","closed_at":"2025-12-10T22:31:12.370724+01:00","dependencies":[{"issue_id":"azul-d2z.21","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:08:14.728744+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.21","depends_on_id":"azul-d2z.19","type":"blocks","created_at":"2025-12-10T22:14:33.564049+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.22","title":"Implement AlphaZeroNet::forward_single","description":"Implement forward_single(\u0026self, obs: \u0026Observation) -\u003e (Array, f32). Reshape obs [obs_size] to [1, obs_size], call forward_batch, squeeze outputs back to [ACTION_SPACE_SIZE] and scalar f32. Used by MCTS for leaf evaluation.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:08:20.888267+01:00","updated_at":"2025-12-10T22:31:17.485126+01:00","closed_at":"2025-12-10T22:31:17.485126+01:00","dependencies":[{"issue_id":"azul-d2z.22","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:08:20.889395+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.22","depends_on_id":"azul-d2z.21","type":"blocks","created_at":"2025-12-10T22:14:38.692974+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.23","title":"Implement PolicyValueNet for AlphaZeroNet","description":"Impl PolicyValueNet for AlphaZeroNet. predict_single delegates to forward_single, predict_batch delegates to forward_batch. This allows AlphaZeroNet to be used with AlphaZeroMctsAgent.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:08:28.063012+01:00","updated_at":"2025-12-10T22:31:22.601823+01:00","closed_at":"2025-12-10T22:31:22.601823+01:00","dependencies":[{"issue_id":"azul-d2z.23","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:08:28.063611+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.23","depends_on_id":"azul-d2z.22","type":"blocks","created_at":"2025-12-10T22:14:43.826494+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.23","depends_on_id":"azul-d2z.4","type":"blocks","created_at":"2025-12-10T22:14:48.956618+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.24","title":"Add mcts module to lib.rs","description":"In crates/rl-env/src/lib.rs: add 'mod mcts;' declaration and 'pub use mcts::{AlphaZeroMctsAgent, MctsConfig, PolicyValueNet};' to expose the MCTS API.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:08:43.453198+01:00","updated_at":"2025-12-10T22:31:27.714854+01:00","closed_at":"2025-12-10T22:31:27.714854+01:00","dependencies":[{"issue_id":"azul-d2z.24","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:08:43.454004+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.24","depends_on_id":"azul-d2z.17","type":"blocks","created_at":"2025-12-10T22:14:57.767256+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.25","title":"Add alphazero_net module to lib.rs","description":"In crates/rl-env/src/lib.rs: add 'mod alphazero_net;' declaration and 'pub use alphazero_net::AlphaZeroNet;' to expose the neural network.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:08:49.837514+01:00","updated_at":"2025-12-10T22:31:32.825398+01:00","closed_at":"2025-12-10T22:31:32.825398+01:00","dependencies":[{"issue_id":"azul-d2z.25","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:08:49.838036+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.25","depends_on_id":"azul-d2z.23","type":"blocks","created_at":"2025-12-10T22:15:02.912253+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.26","title":"Define TrainingExample and Batch structs (outline)","description":"Define TrainingExample { observation: Observation, policy_target: [f32; ACTION_SPACE_SIZE], value_target: f32 } and Batch { observations: Array, policy_targets: Array, value_targets: Array }. These are placeholders for future training pipeline integration.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-10T22:08:55.87538+01:00","updated_at":"2025-12-10T22:35:17.157063+01:00","closed_at":"2025-12-10T22:35:17.157063+01:00","dependencies":[{"issue_id":"azul-d2z.26","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:08:55.875997+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.26","depends_on_id":"azul-d2z.4","type":"blocks","created_at":"2025-12-10T22:15:08.059402+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.27","title":"Test: AlphaZeroNet shape sanity check","description":"Unit test: create AlphaZeroNet, pass zeros observation, verify policy_logits.shape() == [ACTION_SPACE_SIZE] and value in [-1, 1]. Tests that network dimensions are correct.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:09:17.773318+01:00","updated_at":"2025-12-10T22:31:37.937122+01:00","closed_at":"2025-12-10T22:31:37.937122+01:00","dependencies":[{"issue_id":"azul-d2z.27","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:09:17.773858+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.27","depends_on_id":"azul-d2z.23","type":"blocks","created_at":"2025-12-10T22:15:15.67683+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.28","title":"Test: AlphaZeroNet determinism","description":"Unit test: create AlphaZeroNet, call predict_single twice with same input, verify outputs are identical. Tests that network inference is deterministic.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:09:23.881168+01:00","updated_at":"2025-12-10T22:31:43.043098+01:00","closed_at":"2025-12-10T22:31:43.043098+01:00","dependencies":[{"issue_id":"azul-d2z.28","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:09:23.881685+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.28","depends_on_id":"azul-d2z.23","type":"blocks","created_at":"2025-12-10T22:15:20.816466+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.29","title":"Test: Create DummyNet for MCTS testing","description":"Create DummyNet struct implementing PolicyValueNet with fixed priors and value fields. Used for testing MCTS logic independently of real neural network. predict_single returns (Array::from_slice(\u0026priors), value).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:09:29.739199+01:00","updated_at":"2025-12-10T22:33:15.360611+01:00","closed_at":"2025-12-10T22:33:15.360611+01:00","dependencies":[{"issue_id":"azul-d2z.29","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:09:29.739688+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.29","depends_on_id":"azul-d2z.4","type":"blocks","created_at":"2025-12-10T22:15:25.951712+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.3","title":"Update existing tests for new AgentInput signature","description":"Update all tests that construct AgentInput manually to include 'state: None' or appropriate state reference. Primarily affects agent.rs tests for RandomAgent.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:05:11.76422+01:00","updated_at":"2025-12-10T22:22:36.194655+01:00","closed_at":"2025-12-10T22:22:36.194655+01:00","dependencies":[{"issue_id":"azul-d2z.3","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:05:11.764784+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.3","depends_on_id":"azul-d2z.1","type":"blocks","created_at":"2025-12-10T22:11:38.116555+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.30","title":"Test: Root priors respected with 1 simulation","description":"Unit test: num_simulations=1, DummyNet with priors peaked on known legal action. After run_search, verify resulting pi has maximum at that action. Tests that network priors influence initial policy.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:09:37.114111+01:00","updated_at":"2025-12-10T22:33:20.476905+01:00","closed_at":"2025-12-10T22:33:20.476905+01:00","dependencies":[{"issue_id":"azul-d2z.30","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:09:37.114622+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.30","depends_on_id":"azul-d2z.17","type":"blocks","created_at":"2025-12-10T22:15:50.174925+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.30","depends_on_id":"azul-d2z.29","type":"blocks","created_at":"2025-12-10T22:15:55.308526+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.31","title":"Test: Masking respected - no illegal actions selected","description":"Unit test: create AgentInput with some actions illegal (mask[id]=false), DummyNet uniform priors. Verify agent.select_action never returns an illegal action over many trials.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:09:43.007491+01:00","updated_at":"2025-12-10T22:33:25.59691+01:00","closed_at":"2025-12-10T22:33:25.59691+01:00","dependencies":[{"issue_id":"azul-d2z.31","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:09:43.008294+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.31","depends_on_id":"azul-d2z.17","type":"blocks","created_at":"2025-12-10T22:16:00.452199+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.31","depends_on_id":"azul-d2z.29","type":"blocks","created_at":"2025-12-10T22:16:05.586062+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.32","title":"Test: Search improves winning move detection","description":"Unit test: construct toy GameState with immediate winning move. DummyNet uniform priors, 0 value. After many simulations, verify winning action has highest visit count and select_action returns it. Tests that MCTS discovers good moves through search.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:09:49.372274+01:00","updated_at":"2025-12-10T22:33:30.710922+01:00","closed_at":"2025-12-10T22:33:30.710922+01:00","dependencies":[{"issue_id":"azul-d2z.32","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:09:49.372849+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.32","depends_on_id":"azul-d2z.17","type":"blocks","created_at":"2025-12-10T22:16:10.724028+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.32","depends_on_id":"azul-d2z.29","type":"blocks","created_at":"2025-12-10T22:16:15.87035+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.33","title":"Integration test: MCTS agent selects legal actions","description":"Integration test with AzulEnv. Create env with include_full_state_in_step=true, DummyNet agent. Reset env, construct AgentInput from step, call select_action, verify returned action_id is legal (step.legal_action_mask[id] == true).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:10:12.163994+01:00","updated_at":"2025-12-10T22:33:35.827215+01:00","closed_at":"2025-12-10T22:33:35.827215+01:00","dependencies":[{"issue_id":"azul-d2z.33","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:10:12.164516+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.33","depends_on_id":"azul-d2z.24","type":"blocks","created_at":"2025-12-10T22:16:25.521773+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.33","depends_on_id":"azul-d2z.29","type":"blocks","created_at":"2025-12-10T22:16:30.650179+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.34","title":"Integration test: Full game smoke test with MCTS","description":"Integration test: run complete game using AlphaZeroMctsAgent with small num_simulations (16). Loop until env.step returns done==true. Verify game_state.phase == GameOver and assert_tile_invariants passes. Similar to existing RandomAgent test.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:10:18.699905+01:00","updated_at":"2025-12-10T22:33:40.955835+01:00","closed_at":"2025-12-10T22:33:40.955835+01:00","dependencies":[{"issue_id":"azul-d2z.34","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:10:18.700409+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.34","depends_on_id":"azul-d2z.24","type":"blocks","created_at":"2025-12-10T22:16:35.784938+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.35","title":"Integration test: MCTS determinism with fixed seeds","description":"Integration test: fix env RNG seed and MCTS agent RNG seed. Run full episode recording action sequence. Re-run with same seeds. Verify identical action sequence and final scores. Tests reproducibility of MCTS search.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:10:25.793193+01:00","updated_at":"2025-12-10T22:33:46.08661+01:00","closed_at":"2025-12-10T22:33:46.08661+01:00","dependencies":[{"issue_id":"azul-d2z.35","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:10:25.793775+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.35","depends_on_id":"azul-d2z.24","type":"blocks","created_at":"2025-12-10T22:16:40.921817+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.36","title":"Update RandomAgent tests for new AgentInput","description":"Update existing RandomAgent unit tests in agent.rs to pass 'state: None' (or step.state.as_ref()) when constructing AgentInput. Ensures backward compatibility and tests compile after AgentInput change.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:10:32.141628+01:00","updated_at":"2025-12-10T22:31:48.165502+01:00","closed_at":"2025-12-10T22:31:48.165502+01:00","dependencies":[{"issue_id":"azul-d2z.36","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:10:32.142231+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.36","depends_on_id":"azul-d2z.3","type":"blocks","created_at":"2025-12-10T22:16:48.328493+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.37","title":"Add test verifying AgentInput.state is Some when config enabled","description":"Small test: create AzulEnv with include_full_state_in_step=true, reset, verify step.state.is_some(). This documents the contract that MCTS depends on.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:10:38.023106+01:00","updated_at":"2025-12-10T22:33:51.197534+01:00","closed_at":"2025-12-10T22:33:51.197534+01:00","dependencies":[{"issue_id":"azul-d2z.37","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:10:38.023607+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.37","depends_on_id":"azul-d2z.2","type":"blocks","created_at":"2025-12-10T22:16:53.433245+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.38","title":"Create mcts.rs module file","description":"Create new file crates/rl-env/src/mcts.rs. This module will contain all MCTS-related types: PolicyValueNet trait, MctsConfig, ChildEdge, Node, MctsTree, AlphaZeroMctsAgent, and helper functions.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:10:53.206672+01:00","updated_at":"2025-12-10T22:29:08.82044+01:00","closed_at":"2025-12-10T22:29:08.82044+01:00","dependencies":[{"issue_id":"azul-d2z.38","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:10:53.207197+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.38","depends_on_id":"azul-d2z.1","type":"blocks","created_at":"2025-12-10T22:11:45.756857+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.39","title":"Run cargo test -p azul-rl-env","description":"Run 'cargo test -p azul-rl-env' to verify all MCTS and AlphaZeroNet tests pass. This is the final validation step for the implementation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:11:00.051148+01:00","updated_at":"2025-12-10T22:34:14.074701+01:00","closed_at":"2025-12-10T22:34:14.074701+01:00","dependencies":[{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:11:00.051665+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.27","type":"blocks","created_at":"2025-12-10T22:17:01.351495+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.28","type":"blocks","created_at":"2025-12-10T22:17:06.456238+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.30","type":"blocks","created_at":"2025-12-10T22:17:11.564549+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.31","type":"blocks","created_at":"2025-12-10T22:17:16.675722+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.32","type":"blocks","created_at":"2025-12-10T22:17:21.78231+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.33","type":"blocks","created_at":"2025-12-10T22:17:26.886283+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.34","type":"blocks","created_at":"2025-12-10T22:17:31.998355+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.35","type":"blocks","created_at":"2025-12-10T22:17:37.104295+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.36","type":"blocks","created_at":"2025-12-10T22:17:42.211165+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.39","depends_on_id":"azul-d2z.37","type":"blocks","created_at":"2025-12-10T22:17:47.326345+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.4","title":"Define PolicyValueNet trait","description":"Create PolicyValueNet trait in mcts.rs with predict_single(obs) -\u003e (Array, f32) and predict_batch(obs_batch) -\u003e (Array, Array). This abstraction allows MCTS to work with any neural network implementation. Single-example shapes: obs [obs_size], policy_logits [ACTION_SPACE_SIZE], value scalar.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:05:31.106809+01:00","updated_at":"2025-12-10T22:29:45.568171+01:00","closed_at":"2025-12-10T22:29:45.568171+01:00","dependencies":[{"issue_id":"azul-d2z.4","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:05:31.107796+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.4","depends_on_id":"azul-d2z.38","type":"blocks","created_at":"2025-12-10T22:11:50.894966+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.40","title":"Run cargo test -p azul for workspace check","description":"Run 'cargo test -p azul' to verify workspace-level integration works correctly with the new MCTS module.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:11:06.318739+01:00","updated_at":"2025-12-10T22:34:19.198716+01:00","closed_at":"2025-12-10T22:34:19.198716+01:00","dependencies":[{"issue_id":"azul-d2z.40","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:11:06.319259+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.40","depends_on_id":"azul-d2z.39","type":"blocks","created_at":"2025-12-10T22:17:53.29793+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.5","title":"Define MctsConfig struct","description":"Create MctsConfig with fields: num_simulations (u32, default 256), cpuct (f32, default 1.5), root_dirichlet_eps (f32, default 0.25), root_dirichlet_alpha (f32, default 0.3), temperature (f32, default 1.0), max_depth (u32, default 200). Include Default impl.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:05:37.10474+01:00","updated_at":"2025-12-10T22:29:50.68342+01:00","closed_at":"2025-12-10T22:29:50.68342+01:00","dependencies":[{"issue_id":"azul-d2z.5","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:05:37.105345+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.5","depends_on_id":"azul-d2z.38","type":"blocks","created_at":"2025-12-10T22:11:56.030416+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.6","title":"Define MCTS node types (ChildEdge, Node, MctsTree)","description":"Define: NodeIdx = u32 type alias. ChildEdge with action_id, prior, visit_count, value_sum, child: Option\u003cNodeIdx\u003e. Node with state: GameState, to_play: PlayerIdx, is_terminal: bool, children: Vec\u003cChildEdge\u003e, visit_count: u32. MctsTree with nodes: Vec\u003cNode\u003e. Store full GameState in each node for simplicity.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-10T22:05:44.692431+01:00","updated_at":"2025-12-10T22:29:55.788838+01:00","closed_at":"2025-12-10T22:29:55.788838+01:00","dependencies":[{"issue_id":"azul-d2z.6","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:05:44.693379+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.6","depends_on_id":"azul-d2z.38","type":"blocks","created_at":"2025-12-10T22:12:01.16134+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.7","title":"Implement softmax over legal logits helper","description":"Implement softmax(logits: \u0026[(ActionId, f32)]) -\u003e Vec\u003c(ActionId, f32)\u003e helper. Uses numerical stability trick: subtract max logit before exp. Only computes softmax over legal actions, returns normalized priors P(s,a) for each legal action.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:06:06.392912+01:00","updated_at":"2025-12-10T22:30:00.898447+01:00","closed_at":"2025-12-10T22:30:00.898447+01:00","dependencies":[{"issue_id":"azul-d2z.7","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:06:06.393438+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.7","depends_on_id":"azul-d2z.38","type":"blocks","created_at":"2025-12-10T22:12:08.428348+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.8","title":"Implement apply_temperature helper","description":"Implement apply_temperature(counts: \u0026[f32; ACTION_SPACE_SIZE], tau: f32) -\u003e [f32; ACTION_SPACE_SIZE]. For tau \u003c= 1e-6: argmax (set pi[a*]=1, others 0). For tau \u003e 0: pi(a) ∝ N(a)^(1/tau). Converts visit counts to policy distribution.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:06:12.832305+01:00","updated_at":"2025-12-10T22:30:06.002824+01:00","closed_at":"2025-12-10T22:30:06.002824+01:00","dependencies":[{"issue_id":"azul-d2z.8","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:06:12.832896+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.8","depends_on_id":"azul-d2z.38","type":"blocks","created_at":"2025-12-10T22:12:13.5628+01:00","created_by":"bkase"}]}
{"id":"azul-d2z.9","title":"Implement sample_from_policy helper","description":"Implement sample_from_policy(pi: \u0026[f32; ACTION_SPACE_SIZE], tau: f32, rng: \u0026mut impl Rng) -\u003e usize. For tau≈0: return argmax. For tau\u003e0: sample according to pi distribution. Used by AlphaZeroMctsAgent::select_action to pick final move.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-10T22:06:19.821954+01:00","updated_at":"2025-12-10T22:30:11.103101+01:00","closed_at":"2025-12-10T22:30:11.103101+01:00","dependencies":[{"issue_id":"azul-d2z.9","depends_on_id":"azul-d2z","type":"parent-child","created_at":"2025-12-10T22:06:19.822484+01:00","created_by":"bkase"},{"issue_id":"azul-d2z.9","depends_on_id":"azul-d2z.38","type":"blocks","created_at":"2025-12-10T22:12:18.69096+01:00","created_by":"bkase"}]}
{"id":"azul-e9k","title":"Game Engine","description":"Core game logic, rules, state management, move validation for Azul board game","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-09T21:14:20.747626+01:00","updated_at":"2025-12-09T22:28:07.24422+01:00","closed_at":"2025-12-09T22:28:07.24422+01:00","labels":["game-engine","rust"]}
{"id":"azul-e9k.1","title":"Basic types and constants","description":"Implement Section 3.1: PlayerIdx, Row, Col types; BOARD_SIZE, MAX_PLAYERS, MAX_FACTORIES, FACTORY_CAPACITY, FLOOR_CAPACITY, TILE_COLORS, TILES_PER_COLOR constants; Color enum with Blue/Yellow/Red/Black/Teal; ALL_COLORS array; FLOOR_PENALTY array [-1,-1,-2,-2,-2,-3,-3]; Phase enum (FactoryOffer, GameOver)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:05:58.750996+01:00","updated_at":"2025-12-09T22:21:07.62733+01:00","closed_at":"2025-12-09T22:21:07.62733+01:00","dependencies":[{"issue_id":"azul-e9k.1","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:05:58.751696+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.10","title":"legal_actions function","description":"Implement Section 5.2: legal_actions(state) -\u003e Vec\u003cAction\u003e. Enumerate all (source, color) pairs from factories and center. For each, compute allowed destinations checking: wall constraint (color not already in row), pattern line homogeneity, line not full. Always allow Floor destination","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:07:16.602702+01:00","updated_at":"2025-12-09T22:21:55.531897+01:00","closed_at":"2025-12-09T22:21:55.531897+01:00","dependencies":[{"issue_id":"azul-e9k.10","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:07:16.603265+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.10","depends_on_id":"azul-e9k.6","type":"blocks","created_at":"2025-12-09T22:11:50.372633+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.10","depends_on_id":"azul-e9k.7","type":"blocks","created_at":"2025-12-09T22:11:56.507516+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.10","depends_on_id":"azul-e9k.2","type":"blocks","created_at":"2025-12-09T22:12:03.015404+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.11","title":"apply_action function - validity checks","description":"Implement Section 5.3.1: Check phase == FactoryOffer, validate action is in legal_actions. Return ApplyError enum (NotPlayersTurn, WrongPhase, IllegalAction) on failure","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:07:22.843467+01:00","updated_at":"2025-12-09T22:22:02.602017+01:00","closed_at":"2025-12-09T22:22:02.602017+01:00","dependencies":[{"issue_id":"azul-e9k.11","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:07:22.844335+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.11","depends_on_id":"azul-e9k.10","type":"blocks","created_at":"2025-12-09T22:12:09.540341+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.12","title":"apply_action - extract tiles from source","description":"Implement Section 5.3.2 part 1: Extract tiles of chosen color from factory (move others to center) or from center (also take first player marker if present and not yet taken this round). Track took_first_player_marker flag","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:07:29.086386+01:00","updated_at":"2025-12-09T22:22:07.723771+01:00","closed_at":"2025-12-09T22:22:07.723771+01:00","dependencies":[{"issue_id":"azul-e9k.12","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:07:29.086917+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.12","depends_on_id":"azul-e9k.6","type":"blocks","created_at":"2025-12-09T22:12:15.587498+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.13","title":"apply_action - place tiles into destination","description":"Implement Section 5.3.2 part 2: Place tiles into Floor (overflow to discard) or PatternLine (fill up to capacity, overflow to floor then discard). Handle first player marker placement on floor","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:07:35.338018+01:00","updated_at":"2025-12-09T22:22:12.852081+01:00","closed_at":"2025-12-09T22:22:12.852081+01:00","dependencies":[{"issue_id":"azul-e9k.13","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:07:35.338804+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.13","depends_on_id":"azul-e9k.12","type":"blocks","created_at":"2025-12-09T22:12:22.076202+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.14","title":"apply_action - round end check and player advance","description":"Implement Section 5.3.2 part 3: After action, if all factories empty and center has no tiles, call resolve_end_of_round. Otherwise advance current_player to next. Return StepResult with state and optional final_scores","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:07:41.626585+01:00","updated_at":"2025-12-09T22:22:17.980027+01:00","closed_at":"2025-12-09T22:22:17.980027+01:00","dependencies":[{"issue_id":"azul-e9k.14","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:07:41.627315+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.14","depends_on_id":"azul-e9k.11","type":"blocks","created_at":"2025-12-09T22:12:39.390831+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.14","depends_on_id":"azul-e9k.13","type":"blocks","created_at":"2025-12-09T22:12:44.499253+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.15","title":"resolve_end_of_round - wall tiling","description":"Implement Section 5.3.3 step 1: For each player, for each complete pattern line, move rightmost tile to wall at correct column (via WALL_DEST_COL), call score_placement, discard remaining tiles (cap-1), reset pattern line","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:08:05.780583+01:00","updated_at":"2025-12-09T22:22:23.092679+01:00","closed_at":"2025-12-09T22:22:23.092679+01:00","dependencies":[{"issue_id":"azul-e9k.15","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:08:05.78158+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.15","depends_on_id":"azul-e9k.6","type":"blocks","created_at":"2025-12-09T22:12:50.784239+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.15","depends_on_id":"azul-e9k.2","type":"blocks","created_at":"2025-12-09T22:12:55.903224+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.15","depends_on_id":"azul-e9k.16","type":"blocks","created_at":"2025-12-09T22:13:01.916749+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.16","title":"score_placement function","description":"Implement placement scoring per Section 2.2: Count contiguous tiles horizontally and vertically including placed tile. If both counts are 1 (isolated), score 1. Otherwise score (horiz\u003e1 ? horiz : 0) + (vert\u003e1 ? vert : 0)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:08:11.808638+01:00","updated_at":"2025-12-09T22:22:29.67786+01:00","closed_at":"2025-12-09T22:22:29.67786+01:00","dependencies":[{"issue_id":"azul-e9k.16","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:08:11.809608+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.16","depends_on_id":"azul-e9k.5","type":"blocks","created_at":"2025-12-09T22:13:08.122752+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.17","title":"resolve_end_of_round - floor penalties","description":"Implement Section 5.3.3 step 2: For each player, apply FLOOR_PENALTY for each floor slot, clamp score \u003e= 0. Discard floor tiles, track first player marker holder to set starting_player_next_round","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:08:18.006304+01:00","updated_at":"2025-12-09T22:22:34.792473+01:00","closed_at":"2025-12-09T22:22:34.792473+01:00","dependencies":[{"issue_id":"azul-e9k.17","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:08:18.007203+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.17","depends_on_id":"azul-e9k.15","type":"blocks","created_at":"2025-12-09T22:13:15.052155+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.18","title":"resolve_end_of_round - game end check","description":"Implement Section 5.3.3 step 3: Check if any player has complete horizontal wall row (5 tiles). If so, set final_round_triggered=true, call apply_final_scoring, set phase=GameOver, return scores","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:08:24.332323+01:00","updated_at":"2025-12-09T22:22:39.908433+01:00","closed_at":"2025-12-09T22:22:39.908433+01:00","dependencies":[{"issue_id":"azul-e9k.18","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:08:24.33289+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.18","depends_on_id":"azul-e9k.17","type":"blocks","created_at":"2025-12-09T22:13:21.36313+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.18","depends_on_id":"azul-e9k.21","type":"blocks","created_at":"2025-12-09T22:13:26.466172+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.19","title":"resolve_end_of_round - prepare next round","description":"Implement Section 5.3.3 step 4: Increment round, call refill_factories, clear center and add first player marker, set current_player = starting_player_next_round, set phase = FactoryOffer","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:08:30.353224+01:00","updated_at":"2025-12-09T22:22:45.057107+01:00","closed_at":"2025-12-09T22:22:45.057107+01:00","dependencies":[{"issue_id":"azul-e9k.19","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:08:30.353804+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.19","depends_on_id":"azul-e9k.18","type":"blocks","created_at":"2025-12-09T22:13:34.100487+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.19","depends_on_id":"azul-e9k.20","type":"blocks","created_at":"2025-12-09T22:13:39.209449+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.2","title":"Wall layout constants","description":"Implement Section 3.2: WALL_PATTERN 5x5 matrix defining color positions (Latin-square pattern); WALL_DEST_COL lookup array mapping (row, color) -\u003e column; precompute at compile time or hand-code","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:06:05.040923+01:00","updated_at":"2025-12-09T22:21:12.742053+01:00","closed_at":"2025-12-09T22:21:12.742053+01:00","dependencies":[{"issue_id":"azul-e9k.2","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:06:05.041469+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.2","depends_on_id":"azul-e9k.1","type":"blocks","created_at":"2025-12-09T22:10:26.649474+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.20","title":"refill_factories function","description":"Implement factory refill: Draw 4 tiles per factory from bag. If bag empties mid-draw, move all discard to bag and continue. If both empty, leave factories partially filled","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:08:36.536319+01:00","updated_at":"2025-12-09T22:22:50.219387+01:00","closed_at":"2025-12-09T22:22:50.219387+01:00","dependencies":[{"issue_id":"azul-e9k.20","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:08:36.536816+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.20","depends_on_id":"azul-e9k.9","type":"blocks","created_at":"2025-12-09T22:13:45.216645+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.21","title":"apply_final_scoring function","description":"Implement Section 5.3.4: For each player add +2 per complete horizontal row (5 tiles), +7 per complete vertical column, +10 per color with all 5 tiles on wall. Return scores array","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:08:43.316123+01:00","updated_at":"2025-12-09T22:22:55.375988+01:00","closed_at":"2025-12-09T22:22:55.375988+01:00","dependencies":[{"issue_id":"azul-e9k.21","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:08:43.316654+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.21","depends_on_id":"azul-e9k.5","type":"blocks","created_at":"2025-12-09T22:13:52.537664+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.22","title":"Test: Tile count invariants","description":"Implement debug assertion tests per Section 8.2: For each color, verify bag + discard + factories + center + player boards = 20. Run after every apply_action in debug builds","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:09:12.810276+01:00","updated_at":"2025-12-09T22:26:36.147394+01:00","closed_at":"2025-12-09T22:26:36.147394+01:00","dependencies":[{"issue_id":"azul-e9k.22","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:09:12.810846+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.22","depends_on_id":"azul-e9k.14","type":"blocks","created_at":"2025-12-09T22:14:10.257823+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.23","title":"Test: Pattern line and floor invariants","description":"Implement Section 8.2 tests: floor.len \u003c= 7; pattern line count \u003c= capacity; count==0 iff color==None; wall positions match WALL_PATTERN colors; player indices valid","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:09:19.22551+01:00","updated_at":"2025-12-09T22:26:41.201909+01:00","closed_at":"2025-12-09T22:26:41.201909+01:00","dependencies":[{"issue_id":"azul-e9k.23","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:09:19.225969+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.23","depends_on_id":"azul-e9k.6","type":"blocks","created_at":"2025-12-09T22:14:16.565093+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.24","title":"Test: Placement scoring scenarios","description":"Per Section 8.3: Test score_placement with isolated tile (=1), horizontal group, vertical group, cross shape. Verify adjacency counting is correct","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:09:25.320175+01:00","updated_at":"2025-12-09T22:26:46.257882+01:00","closed_at":"2025-12-09T22:26:46.257882+01:00","dependencies":[{"issue_id":"azul-e9k.24","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:09:25.320644+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.24","depends_on_id":"azul-e9k.16","type":"blocks","created_at":"2025-12-09T22:14:22.459875+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.25","title":"Test: Floor penalty calculation","description":"Test full floor of 7 tiles gives penalty -14 (-1-1-2-2-2-3-3). Verify score clamps to \u003e= 0. Test partial floor penalties","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:09:31.564862+01:00","updated_at":"2025-12-09T22:26:51.411217+01:00","closed_at":"2025-12-09T22:26:51.411217+01:00","dependencies":[{"issue_id":"azul-e9k.25","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:09:31.565415+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.25","depends_on_id":"azul-e9k.17","type":"blocks","created_at":"2025-12-09T22:14:28.615106+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.26","title":"Test: Endgame bonus calculation","description":"Test apply_final_scoring: +2 per horizontal row, +7 per vertical column, +10 per complete color set. Test player with 1 row + 1 column + 1 color = +19","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:09:37.76383+01:00","updated_at":"2025-12-09T22:26:56.571087+01:00","closed_at":"2025-12-09T22:26:56.571087+01:00","dependencies":[{"issue_id":"azul-e9k.26","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:09:37.764748+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.26","depends_on_id":"azul-e9k.21","type":"blocks","created_at":"2025-12-09T22:14:35.182524+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.27","title":"Test: Factory refill from depleted bag","description":"Test refill_factories when bag has few tiles, discard has rest. Verify tiles move from discard to bag mid-refill. Test edge case where both empty","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:09:43.873296+01:00","updated_at":"2025-12-09T22:27:35.925321+01:00","closed_at":"2025-12-09T22:27:35.925321+01:00","dependencies":[{"issue_id":"azul-e9k.27","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:09:43.873839+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.27","depends_on_id":"azul-e9k.20","type":"blocks","created_at":"2025-12-09T22:14:41.279712+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.28","title":"Test: Legal actions enumeration","description":"Test legal_actions respects: wall constraint (can't place color already in wall row), pattern line homogeneity, line capacity. Test Floor always available","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:09:50.177818+01:00","updated_at":"2025-12-09T22:27:40.992146+01:00","closed_at":"2025-12-09T22:27:40.992146+01:00","dependencies":[{"issue_id":"azul-e9k.28","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:09:50.178457+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.28","depends_on_id":"azul-e9k.10","type":"blocks","created_at":"2025-12-09T22:14:47.608453+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.29","title":"Test: First player marker mechanics","description":"Test: marker starts in center, first center pick takes it, marker goes to floor, marker holder becomes next round starter, marker incurs floor penalty","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:09:56.253863+01:00","updated_at":"2025-12-09T22:27:46.150321+01:00","closed_at":"2025-12-09T22:27:46.150321+01:00","dependencies":[{"issue_id":"azul-e9k.29","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:09:56.254879+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.29","depends_on_id":"azul-e9k.19","type":"blocks","created_at":"2025-12-09T22:14:54.654256+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.3","title":"Factory and Center data structures","description":"Implement Section 3.3: Factory struct (len: u8, tiles: [Color; 4]); Factories struct (num_factories: u8, factories: [Factory; 9]); Token enum (Tile(Color), FirstPlayerMarker); CenterPool struct (len: u8, items: [Token; 100])","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:06:11.212524+01:00","updated_at":"2025-12-09T22:21:17.86716+01:00","closed_at":"2025-12-09T22:21:17.86716+01:00","dependencies":[{"issue_id":"azul-e9k.3","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:06:11.213143+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.3","depends_on_id":"azul-e9k.1","type":"blocks","created_at":"2025-12-09T22:10:32.681968+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.30","title":"Test: Full game simulation","description":"Run multiple complete games (2/3/4 players) with random legal moves until GameOver. Verify no panics, invariants hold throughout, final scores computed correctly","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:10:02.30987+01:00","updated_at":"2025-12-09T22:27:51.277291+01:00","closed_at":"2025-12-09T22:27:51.277291+01:00","dependencies":[{"issue_id":"azul-e9k.30","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:10:02.310319+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.30","depends_on_id":"azul-e9k.19","type":"blocks","created_at":"2025-12-09T22:15:00.832937+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.30","depends_on_id":"azul-e9k.8","type":"blocks","created_at":"2025-12-09T22:15:05.940189+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.31","title":"Test: Deterministic replay","description":"Given same RNG seed and action sequence, verify game plays out identically. Important for RL reproducibility","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:10:08.745559+01:00","updated_at":"2025-12-09T22:27:56.396647+01:00","closed_at":"2025-12-09T22:27:56.396647+01:00","dependencies":[{"issue_id":"azul-e9k.31","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:10:08.746143+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.31","depends_on_id":"azul-e9k.30","type":"blocks","created_at":"2025-12-09T22:15:11.980142+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.4","title":"TileSupply (bag and discard)","description":"Implement Section 3.4: TileSupply struct with bag: [u8; 5] and discard: [u8; 5] for color counts; document tile count invariant (bag + discard + factories + center + players = 20 per color)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:06:17.335361+01:00","updated_at":"2025-12-09T22:21:22.993975+01:00","closed_at":"2025-12-09T22:21:22.993975+01:00","dependencies":[{"issue_id":"azul-e9k.4","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:06:17.335944+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.4","depends_on_id":"azul-e9k.1","type":"blocks","created_at":"2025-12-09T22:10:38.710219+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.5","title":"Player board state structures","description":"Implement Section 3.5: PatternLine struct (color: Option\u003cColor\u003e, count: u8); Wall type as [[Option\u003cColor\u003e; 5]; 5]; FloorLine struct (len: u8, slots: [Token; 7]); PlayerState struct (wall, pattern_lines, floor, score: i16)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:06:23.387045+01:00","updated_at":"2025-12-09T22:21:28.119061+01:00","closed_at":"2025-12-09T22:21:28.119061+01:00","dependencies":[{"issue_id":"azul-e9k.5","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:06:23.387614+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.5","depends_on_id":"azul-e9k.1","type":"blocks","created_at":"2025-12-09T22:10:44.86358+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.5","depends_on_id":"azul-e9k.3","type":"blocks","created_at":"2025-12-09T22:10:51.279464+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.6","title":"Top-level GameState struct","description":"Implement Section 3.6: GameState struct combining all components - num_players, players array, factories, center, supply, current_player, starting_player_next_round, phase, round counter, final_round_triggered flag","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:06:30.107555+01:00","updated_at":"2025-12-09T22:21:35.019051+01:00","closed_at":"2025-12-09T22:21:35.019051+01:00","dependencies":[{"issue_id":"azul-e9k.6","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:06:30.108062+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.6","depends_on_id":"azul-e9k.3","type":"blocks","created_at":"2025-12-09T22:10:57.764519+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.6","depends_on_id":"azul-e9k.4","type":"blocks","created_at":"2025-12-09T22:11:03.834561+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.6","depends_on_id":"azul-e9k.5","type":"blocks","created_at":"2025-12-09T22:11:09.978924+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.7","title":"Action representation","description":"Implement Section 4: DraftSource enum (Factory(u8), Center); DraftDestination enum (PatternLine(Row), Floor); Action struct (source, color, dest). Tiles taken implied by board state, overflow to floor is automatic","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:06:36.590845+01:00","updated_at":"2025-12-09T22:21:40.146827+01:00","closed_at":"2025-12-09T22:21:40.146827+01:00","dependencies":[{"issue_id":"azul-e9k.7","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:06:36.591414+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.7","depends_on_id":"azul-e9k.1","type":"blocks","created_at":"2025-12-09T22:11:15.893134+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.8","title":"new_game function","description":"Implement Section 5.1: new_game(num_players, starting_player, rng) -\u003e GameState. Initialize empty player states, bag with 20 tiles per color, draw 4 tiles per factory (5/7/9 factories for 2/3/4 players), place first player marker in center, set phase to FactoryOffer","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:07:02.160076+01:00","updated_at":"2025-12-09T22:21:45.281736+01:00","closed_at":"2025-12-09T22:21:45.281736+01:00","dependencies":[{"issue_id":"azul-e9k.8","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:07:02.160992+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.8","depends_on_id":"azul-e9k.6","type":"blocks","created_at":"2025-12-09T22:11:31.930413+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.8","depends_on_id":"azul-e9k.9","type":"blocks","created_at":"2025-12-09T22:11:38.046268+01:00","created_by":"bkase"}]}
{"id":"azul-e9k.9","title":"Random tile drawing helper","description":"Implement helper function to draw N random tiles from bag. When bag empties, refill from discard. Handle partial fills if both empty. Used by new_game and refill_factories","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-09T22:07:09.849299+01:00","updated_at":"2025-12-09T22:21:50.403363+01:00","closed_at":"2025-12-09T22:21:50.403363+01:00","dependencies":[{"issue_id":"azul-e9k.9","depends_on_id":"azul-e9k","type":"parent-child","created_at":"2025-12-09T22:07:09.850121+01:00","created_by":"bkase"},{"issue_id":"azul-e9k.9","depends_on_id":"azul-e9k.4","type":"blocks","created_at":"2025-12-09T22:11:44.291162+01:00","created_by":"bkase"}]}
{"id":"azul-iqm","title":"Make checkpoint-dir required by default with --no-checkpoints opt-out","description":"Change checkpoint-dir from optional to required by default. Add --no-checkpoints flag to disable checkpointing entirely (for quick experiments/profiling). When --no-checkpoints is passed, checkpoint-dir becomes optional. This ensures training runs always save progress unless explicitly disabled.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T01:06:54.575478+01:00","updated_at":"2025-12-11T01:15:14.279486+01:00","closed_at":"2025-12-11T01:15:14.279486+01:00","dependencies":[{"issue_id":"azul-iqm","depends_on_id":"azul-ctu","type":"blocks","created_at":"2025-12-11T01:06:54.576744+01:00","created_by":"bkase"}]}
{"id":"azul-jba","title":"Training Pipeline","description":"Implement training loop, reward shaping, policy optimization, and model checkpointing","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-09T21:14:39.382282+01:00","updated_at":"2025-12-09T21:14:39.382282+01:00","labels":["mlx","rl","training"]}
{"id":"azul-ku3","title":"Test that gradient application actually changes model outputs","description":"Add test that verifies apply_gradients actually modifies the model. Run forward pass before/after and assert outputs differ. Currently no test validates that training actually updates weights.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:39:00.973997+01:00","updated_at":"2025-12-11T00:44:40.506405+01:00","closed_at":"2025-12-11T00:44:40.506405+01:00","dependencies":[{"issue_id":"azul-ku3","depends_on_id":"azul-3x2","type":"blocks","created_at":"2025-12-11T00:39:42.774941+01:00","created_by":"bkase"}]}
{"id":"azul-n9c","title":"Add debugging tools for RL training: inspect, overfit test, reward scaling fix","description":"","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T13:12:21.541847+01:00","updated_at":"2025-12-14T13:15:38.072825+01:00","closed_at":"2025-12-14T13:15:38.072825+01:00"}
{"id":"azul-nf5","title":"Milestone 4: Low-Hanging Optimizations","description":"Implement obvious performance wins identified from code review: action decode LUT, cached zero observations, stored obs_size, and forward_with_params fix.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-11T00:50:53.666008+01:00","updated_at":"2025-12-11T01:52:09.635071+01:00","closed_at":"2025-12-11T01:52:09.635071+01:00","dependencies":[{"issue_id":"azul-nf5","depends_on_id":"azul-q5a","type":"blocks","created_at":"2025-12-11T00:56:18.857225+01:00","created_by":"bkase"}]}
{"id":"azul-nf5.1","title":"Implement Action decode lookup table","description":"In crates/rl-env/src/action_encoder.rs, precompute static ACTION_LUT: [Action; ACTION_SPACE_SIZE] at startup using lazy_static! or once_cell. Replace decode(id) arithmetic with simple ACTION_LUT[id as usize] lookup. This removes divisions/modulos from MCTS expansion and environment step hot paths.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:54:46.44858+01:00","updated_at":"2025-12-11T01:47:10.851268+01:00","closed_at":"2025-12-11T01:47:10.851268+01:00","dependencies":[{"issue_id":"azul-nf5.1","depends_on_id":"azul-nf5","type":"parent-child","created_at":"2025-12-11T00:54:46.449123+01:00","created_by":"bkase"}]}
{"id":"azul-nf5.2","title":"Cache zero observations","description":"In BasicFeatureExtractor and/or AzulEnv, preallocate a single zero observation (for players beyond num_players) and reuse it instead of calling create_zero_observation() on every step. Nearly free win for 4-player games with 2 active players.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T00:54:52.508148+01:00","updated_at":"2025-12-11T01:48:29.342712+01:00","closed_at":"2025-12-11T01:48:29.342712+01:00","dependencies":[{"issue_id":"azul-nf5.2","depends_on_id":"azul-nf5","type":"parent-child","created_at":"2025-12-11T00:54:52.508838+01:00","created_by":"bkase"}]}
{"id":"azul-nf5.3","title":"Store obs_size in BasicFeatureExtractor","description":"BasicFeatureExtractor::obs_size() currently recomputes calculate_obs_size() every call. Compute once in ::new() and store as field. Tiny but free optimization since obs_size() is called frequently in encode() and create_zero_observation().","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T00:54:58.950593+01:00","updated_at":"2025-12-11T01:47:15.961873+01:00","closed_at":"2025-12-11T01:47:15.961873+01:00","dependencies":[{"issue_id":"azul-nf5.3","depends_on_id":"azul-nf5","type":"parent-child","created_at":"2025-12-11T00:54:58.951146+01:00","created_by":"bkase"}]}
{"id":"azul-nf5.4","title":"Fix forward_with_params to reuse network","description":"In src/main.rs TrainableMctsAgent::forward_with_params: currently creates brand-new AlphaZeroNet every call (ignoring params). Fix to either: (a) properly use provided params, or (b) at minimum reuse the existing network instead of reinitializing. This removes allocation overhead from each FD gradient evaluation.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:55:05.053484+01:00","updated_at":"2025-12-11T01:48:35.433925+01:00","closed_at":"2025-12-11T01:48:35.433925+01:00","dependencies":[{"issue_id":"azul-nf5.4","depends_on_id":"azul-nf5","type":"parent-child","created_at":"2025-12-11T00:55:05.054017+01:00","created_by":"bkase"}]}
{"id":"azul-nf5.5","title":"Re-run benchmarks after optimizations","description":"After implementing optimizations, re-run cargo bench -p azul-rl-env and profiling runs. Compare against baseline from M3. Document improvements in history/optimization_results.md with before/after metrics.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T00:55:11.014176+01:00","updated_at":"2025-12-11T01:52:03.37857+01:00","closed_at":"2025-12-11T01:52:03.37857+01:00","dependencies":[{"issue_id":"azul-nf5.5","depends_on_id":"azul-nf5","type":"parent-child","created_at":"2025-12-11T00:55:11.014724+01:00","created_by":"bkase"},{"issue_id":"azul-nf5.5","depends_on_id":"azul-nf5.1","type":"blocks","created_at":"2025-12-11T00:59:20.552746+01:00","created_by":"bkase"},{"issue_id":"azul-nf5.5","depends_on_id":"azul-nf5.2","type":"blocks","created_at":"2025-12-11T00:59:26.741249+01:00","created_by":"bkase"},{"issue_id":"azul-nf5.5","depends_on_id":"azul-nf5.3","type":"blocks","created_at":"2025-12-11T00:59:32.894618+01:00","created_by":"bkase"},{"issue_id":"azul-nf5.5","depends_on_id":"azul-nf5.4","type":"blocks","created_at":"2025-12-11T00:59:39.662689+01:00","created_by":"bkase"}]}
{"id":"azul-nw8","title":"Remove score clamping to fix Zero-Score Trap","description":"Agent learns to dump tiles to floor instead of playing because scores are clamped at 0. When starting at score=0, floor penalties (negative) get clamped back to 0, making flooring appear safe (0 reward) vs risky plays. Need to allow negative scores to provide proper gradient for learning. Also need to update test_floor_penalty_score_clamp test that expects non-negative scores.","status":"closed","priority":0,"issue_type":"bug","created_at":"2025-12-14T22:32:20.988569Z","updated_at":"2025-12-14T22:36:25.493741Z","closed_at":"2025-12-14T22:36:25.493741Z"}
{"id":"azul-oak","title":"Fix profiling counters and inference batching after worker introduction","description":"Profiling metrics broke after adding the single-thread inference worker: MCTS nodes created and NN eval counts stay zero, timings are per-thread not wall time, and NN batches are too small (~16.7 avg vs batch size 32). Fix counters, add wall-clock iteration timing, and adjust worker batching to reduce tiny batches (bounded queue or coalescing).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-14T22:10:49.241256Z","updated_at":"2025-12-14T22:16:42.912819Z","closed_at":"2025-12-14T22:16:42.912819Z","dependencies":[{"issue_id":"azul-oak","depends_on_id":"azul-pdt.1","type":"discovered-from","created_at":"2025-12-14T22:10:49.24262Z","created_by":"bkase"}]}
{"id":"azul-p5c","title":"Milestone 1: Profiling Infrastructure \u0026 Self-Play Baseline","description":"Set up profiling infrastructure (feature flag, counters, timers) and establish baseline metrics for self-play without training. This is the foundation for all performance analysis.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-11T00:50:33.351924+01:00","updated_at":"2025-12-11T01:34:29.635715+01:00","closed_at":"2025-12-11T01:34:29.635715+01:00"}
{"id":"azul-p5c.1","title":"Add --no-train CLI flag","description":"Add --no-train (or --train=false) CLI flag in src/main.rs that sets training_steps_per_iter=0. This allows profiling self-play/MCTS separately without the training cost.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:51:36.10497+01:00","updated_at":"2025-12-11T01:22:27.481082+01:00","closed_at":"2025-12-11T01:22:27.481082+01:00","dependencies":[{"issue_id":"azul-p5c.1","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:51:36.105486+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.10","title":"Instrument AzulEnv reset and step","description":"In crates/rl-env/src/environment.rs, instrument AzulEnv::reset and AzulEnv::step with timing. Increment env_steps counter in step.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:52:32.636875+01:00","updated_at":"2025-12-11T01:30:09.857354+01:00","closed_at":"2025-12-11T01:30:09.857354+01:00","dependencies":[{"issue_id":"azul-p5c.10","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:52:32.637417+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.10","depends_on_id":"azul-p5c.4","type":"blocks","created_at":"2025-12-11T00:57:24.898882+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.11","title":"Add print_summary helper","description":"In profiling.rs, implement print_summary() that computes human-readable stats from counters: seconds, ops/sec, games/sec, simulations/search, etc. Call from Trainer::run at the end when profiling feature is enabled.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:52:38.803535+01:00","updated_at":"2025-12-11T01:31:21.200927+01:00","closed_at":"2025-12-11T01:31:21.200927+01:00","dependencies":[{"issue_id":"azul-p5c.11","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:52:38.804086+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.11","depends_on_id":"azul-p5c.3","type":"blocks","created_at":"2025-12-11T00:57:30.952802+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.12","title":"Run baseline profiling with --no-train","description":"Execute: cargo run --release --features profiling -- --num-iters 10 --games-per-iter 2 --mcts-sims 20 --no-train. Capture total time, time split, counts: games, moves, env steps, MCTS searches, simulations. Document results as baseline.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:52:45.459694+01:00","updated_at":"2025-12-11T01:34:23.587571+01:00","closed_at":"2025-12-11T01:34:23.587571+01:00","dependencies":[{"issue_id":"azul-p5c.12","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:52:45.460237+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.12","depends_on_id":"azul-p5c.1","type":"blocks","created_at":"2025-12-11T00:57:37.000022+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.12","depends_on_id":"azul-p5c.11","type":"blocks","created_at":"2025-12-11T00:57:43.091692+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.2","title":"Add profiling feature to Cargo.toml","description":"Add optional 'profiling' feature in crates/rl-env/Cargo.toml and top-level Cargo.toml. Convention: all instrumentation code guarded behind #[cfg(feature = \"profiling\")].","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:51:42.373555+01:00","updated_at":"2025-12-11T01:23:02.416393+01:00","closed_at":"2025-12-11T01:23:02.416393+01:00","dependencies":[{"issue_id":"azul-p5c.2","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:51:42.37414+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.3","title":"Create profiling module with Counters struct","description":"Create crates/rl-env/src/profiling.rs (only compiled with profiling feature). Implement Counters struct with AtomicU64 fields for: self_play_games, self_play_moves, mcts_searches, mcts_simulations, mcts_nodes_created, mcts_nn_evals, train_steps, fd_forward_evals, env_steps, nn_batch_forwards. Also add time accumulators: time_self_play_ns, time_training_ns, time_mcts_search_ns, etc.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:51:48.552071+01:00","updated_at":"2025-12-11T01:23:59.641371+01:00","closed_at":"2025-12-11T01:23:59.641371+01:00","dependencies":[{"issue_id":"azul-p5c.3","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:51:48.552596+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.3","depends_on_id":"azul-p5c.2","type":"blocks","created_at":"2025-12-11T00:56:42.102078+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.4","title":"Add Timer RAII struct for scoped timing","description":"In profiling.rs, implement Timer struct that takes \u0026'static AtomicU64 as destination accumulator. On Drop, adds elapsed.as_nanos() to the destination. Usage: let _t = Timer::new(\u0026PROF.time_self_play_ns);","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:51:54.90345+01:00","updated_at":"2025-12-11T01:24:38.798162+01:00","closed_at":"2025-12-11T01:24:38.798162+01:00","dependencies":[{"issue_id":"azul-p5c.4","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:51:54.90404+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.4","depends_on_id":"azul-p5c.2","type":"blocks","created_at":"2025-12-11T00:56:48.503255+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.5","title":"Instrument Trainer::run self-play phase","description":"In crates/rl-env/src/alphazero/training.rs Trainer::run, add Timer around self-play loop. Increment self_play_games and self_play_moves counters after each game.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:52:00.986579+01:00","updated_at":"2025-12-11T01:25:33.876585+01:00","closed_at":"2025-12-11T01:25:33.876585+01:00","dependencies":[{"issue_id":"azul-p5c.5","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:52:00.987211+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.5","depends_on_id":"azul-p5c.4","type":"blocks","created_at":"2025-12-11T00:56:54.460156+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.6","title":"Instrument Trainer::run training phase","description":"In Trainer::run, add Timer around training loop. Increment train_steps counter for each training_step call.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:52:07.639956+01:00","updated_at":"2025-12-11T01:26:15.534063+01:00","closed_at":"2025-12-11T01:26:15.534063+01:00","dependencies":[{"issue_id":"azul-p5c.6","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:52:07.640616+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.6","depends_on_id":"azul-p5c.4","type":"blocks","created_at":"2025-12-11T00:57:00.452886+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.7","title":"Instrument self_play_game internals","description":"In self_play_game function, add Timer for whole game. Inside main while loop, increment env_steps counter for each move.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:52:13.638373+01:00","updated_at":"2025-12-11T01:26:53.565432+01:00","closed_at":"2025-12-11T01:26:53.565432+01:00","dependencies":[{"issue_id":"azul-p5c.7","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:52:13.638933+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.7","depends_on_id":"azul-p5c.4","type":"blocks","created_at":"2025-12-11T00:57:06.730513+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.8","title":"Instrument MCTS run_search","description":"In crates/rl-env/src/mcts.rs AlphaZeroMctsAgent::run_search, add Timer for search duration and increment mcts_searches counter.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:52:19.928564+01:00","updated_at":"2025-12-11T01:27:49.621847+01:00","closed_at":"2025-12-11T01:27:49.621847+01:00","dependencies":[{"issue_id":"azul-p5c.8","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:52:19.929137+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.8","depends_on_id":"azul-p5c.4","type":"blocks","created_at":"2025-12-11T00:57:12.629982+01:00","created_by":"bkase"}]}
{"id":"azul-p5c.9","title":"Instrument MCTS simulate and create_node","description":"Instrument simulate() with timer and mcts_simulations counter. Instrument create_node with mcts_nodes_created counter. Add timer around NN evaluations (predict_single calls) and increment mcts_nn_evals.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:52:26.126745+01:00","updated_at":"2025-12-11T01:29:06.595548+01:00","closed_at":"2025-12-11T01:29:06.595548+01:00","dependencies":[{"issue_id":"azul-p5c.9","depends_on_id":"azul-p5c","type":"parent-child","created_at":"2025-12-11T00:52:26.127296+01:00","created_by":"bkase"},{"issue_id":"azul-p5c.9","depends_on_id":"azul-p5c.4","type":"blocks","created_at":"2025-12-11T00:57:18.738535+01:00","created_by":"bkase"}]}
{"id":"azul-pdt","title":"CPU Parallel MCTS for AlphaZero","description":"After batched NN inference reduces GPU time, CPU MCTS overhead becomes the bottleneck.\nThis epic adds CPU parallelism to scale simulations across cores.\n\n**Context:**\n- With batched NN, MCTS non-NN overhead (~26%) becomes dominant\n- MCTS overhead with dummy net is ~2.2µs/simulation\n- Need CPU parallelism to keep scaling\n\n**Target:**\n- ≥10 games/sec (from ~5-8 games/sec after batching)\n- Scale with performance core count\n\n**Strategies:**\n1. Root-parallel (recommended first): N independent searches, sum visit counts\n2. Tree-parallel (future): Shared tree with atomic updates\n\n**Depends on:** Batched NN Inference (azul-zfs) completing first\n\nPrimary files: mcts.rs, main.rs","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-13T17:52:19.23922+01:00","updated_at":"2025-12-13T17:52:19.23922+01:00","dependencies":[{"issue_id":"azul-pdt","depends_on_id":"azul-zfs","type":"blocks","created_at":"2025-12-13T17:52:29.320986+01:00","created_by":"bkase"}]}
{"id":"azul-pdt.1","title":"Add num_threads and ParallelMode to MctsConfig","description":"Extend MctsConfig with parallelism settings:\n\n```rust\npub enum ParallelMode {\n    None,        // Single-threaded (current behavior)\n    RootParallel, // N independent searches, aggregate root counts\n    // TreeParallel, // Future: shared tree with atomics\n}\n\npub struct MctsConfig {\n    // ... existing fields ...\n    \n    /// Number of CPU threads for MCTS simulations.\n    /// Default: 1 (single-threaded)\n    pub num_threads: usize,\n    \n    /// Parallelization strategy.\n    /// Default: None\n    pub parallel_mode: ParallelMode,\n}\n```\n\nUpdate Default impl:\n- num_threads: 1\n- parallel_mode: ParallelMode::None\n\nLocation: crates/rl-env/src/mcts.rs","status":"in_progress","priority":2,"issue_type":"task","created_at":"2025-12-13T17:52:43.971423+01:00","updated_at":"2025-12-14T21:40:17.437092Z","dependencies":[{"issue_id":"azul-pdt.1","depends_on_id":"azul-pdt","type":"parent-child","created_at":"2025-12-13T17:52:43.972049+01:00","created_by":"bkase"},{"issue_id":"azul-pdt.1","depends_on_id":"azul-zfs","type":"blocks","created_at":"2025-12-13T23:32:19.651632+01:00","created_by":"bkase"}]}
{"id":"azul-pdt.2","title":"Implement run_search_root_parallel with Rayon","description":"Implement root-parallel MCTS search using Rayon:\n\n```rust\nfn run_search_root_parallel(\n    \u0026mut self,\n    root_state: \u0026GameState,\n    rng: \u0026mut impl Rng,\n) -\u003e [f32; ACTION_SPACE_SIZE] {\n    // 1) Build root priors once (including Dirichlet noise)\n    // This is shared across all workers\n    \n    // 2) Spawn N workers using rayon::scope\n    let sims_per_worker = self.config.num_simulations / self.config.num_threads;\n    \n    let visit_counts: Vec\u003c[u32; ACTION_SPACE_SIZE]\u003e = rayon::scope(|s| {\n        // Derive deterministic seeds for each worker\n        let seeds: Vec\u003cu64\u003e = (0..num_threads)\n            .map(|i| rng.gen::\u003cu64\u003e().wrapping_add(i as u64))\n            .collect();\n        \n        // Each worker:\n        // - clones root state\n        // - runs batched-MCTS locally for sims_per_worker simulations\n        // - returns root visit-count array\n    });\n    \n    // 3) Aggregate root visit counts (sum arrays)\n    let mut total_counts = [0u32; ACTION_SPACE_SIZE];\n    for counts in \u0026visit_counts {\n        for (i, c) in counts.iter().enumerate() {\n            total_counts[i] += c;\n        }\n    }\n    \n    // 4) Apply temperature and return policy\n    apply_temperature(\u0026total_counts.map(|c| c as f32), self.config.temperature)\n}\n```\n\nKey considerations:\n- Derive deterministic seeds per worker for reproducibility\n- Each worker has its own tree (no sharing)\n- Aggregate only root visit counts\n\nLocation: crates/rl-env/src/mcts.rs","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T17:53:03.608344+01:00","updated_at":"2025-12-13T17:53:03.608344+01:00","dependencies":[{"issue_id":"azul-pdt.2","depends_on_id":"azul-pdt","type":"parent-child","created_at":"2025-12-13T17:53:03.608926+01:00","created_by":"bkase"},{"issue_id":"azul-pdt.2","depends_on_id":"azul-pdt.1","type":"blocks","created_at":"2025-12-13T17:55:42.572548+01:00","created_by":"bkase"}]}
{"id":"azul-pdt.3","title":"Handle MLX thread-safety for parallel MCTS","description":"Address MLX/AlphaZeroNet thread-safety for parallel execution.\n\n**Problem:** MLX modules are likely not Send + Sync, so we can't share net across Rayon workers.\n\n**Options:**\n\n**Option A1 (Recommended):** Centralized evaluator\n- Keep ALL MLX calls on the main thread\n- Workers send leaf jobs to main thread via channel\n- Main thread batches and evaluates, sends results back\n- More complex but avoids Send issues\n\n**Option A2:** Clone network per worker\n- Each worker gets its own AlphaZeroNet copy\n- May serialize on Metal queue\n- Increases memory usage\n- Simpler to implement\n\n**Implementation steps:**\n1. Add compile-time assert to check if AlphaZeroNet is Send/Sync\n2. If NOT Send: implement Option A1 with crossbeam channels\n3. If Send: can use Option A2 (simpler)\n\n```rust\n// Compile-time check\nfn _assert_send\u003cT: Send\u003e() {}\nfn _check_net_is_send() {\n    // This will fail to compile if AlphaZeroNet is not Send\n    _assert_send::\u003cAlphaZeroNet\u003e();\n}\n```\n\nLocation: crates/rl-env/src/mcts.rs","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T17:53:21.108147+01:00","updated_at":"2025-12-13T17:53:21.108147+01:00","dependencies":[{"issue_id":"azul-pdt.3","depends_on_id":"azul-pdt","type":"parent-child","created_at":"2025-12-13T17:53:21.108723+01:00","created_by":"bkase"},{"issue_id":"azul-pdt.3","depends_on_id":"azul-pdt.2","type":"blocks","created_at":"2025-12-13T17:55:47.715078+01:00","created_by":"bkase"}]}
{"id":"azul-pdt.4","title":"Expose --mcts-threads and --mcts-parallel-mode CLI flags","description":"Add CLI flags to control CPU parallelism:\n\nIn src/main.rs parse_args():\n```rust\n--mcts-threads \u003cN\u003e         // default: 1 (number of CPU threads)\n--mcts-parallel-mode \u003cM\u003e   // default: none, options: none, root\n```\n\nUsage:\n```bash\ncargo run --release -- \\\n  --mcts-threads 4 \\\n  --mcts-parallel-mode root \\\n  ...\n```\n\n**Tuning guidance for Apple Silicon:**\n- Set threads = number of performance cores (not total cores)\n- Use RAYON_NUM_THREADS to control Rayon's thread pool\n- Start with 4-6 threads on M1/M2/M3 chips\n\nLocation: src/main.rs","status":"open","priority":3,"issue_type":"task","created_at":"2025-12-13T17:53:36.087835+01:00","updated_at":"2025-12-13T17:53:36.087835+01:00","dependencies":[{"issue_id":"azul-pdt.4","depends_on_id":"azul-pdt","type":"parent-child","created_at":"2025-12-13T17:53:36.08833+01:00","created_by":"bkase"},{"issue_id":"azul-pdt.4","depends_on_id":"azul-pdt.1","type":"blocks","created_at":"2025-12-13T23:31:47.173056+01:00","created_by":"bkase"}]}
{"id":"azul-pdt.5","title":"Add test_mcts_parallel_matches_single_thread","description":"Add test to verify root-parallel produces similar results to single-threaded:\n\n```rust\n#[test]\nfn test_mcts_parallel_matches_single_thread_dummy_net() {\n    let mut rng = SmallRng::seed_from_u64(42);\n    let state = new_game(2, \u0026mut rng);\n    \n    // Single-threaded config\n    let single_config = MctsConfig {\n        num_simulations: 100,\n        num_threads: 1,\n        parallel_mode: ParallelMode::None,\n        ..Default::default()\n    };\n    \n    // Root-parallel config with same total sims\n    let parallel_config = MctsConfig {\n        num_simulations: 100,\n        num_threads: 4,\n        parallel_mode: ParallelMode::RootParallel,\n        ..Default::default()\n    };\n    \n    // With DummyNet (deterministic), results should be similar\n    // (not identical due to different tree traversals)\n    \n    let single_policy = run_with_config(\u0026state, \u0026single_config);\n    let parallel_policy = run_with_config(\u0026state, \u0026parallel_config);\n    \n    // Both should select same action (highest visit count)\n    let single_action = argmax(\u0026single_policy);\n    let parallel_action = argmax(\u0026parallel_policy);\n    \n    // With enough simulations, top action should match\n    assert_eq!(single_action, parallel_action, \n        \"Top action should match between single and parallel\");\n}\n```\n\nLocation: crates/rl-env/src/mcts.rs (in #[cfg(test)] mod tests)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T17:53:53.570193+01:00","updated_at":"2025-12-13T17:53:53.570193+01:00","dependencies":[{"issue_id":"azul-pdt.5","depends_on_id":"azul-pdt","type":"parent-child","created_at":"2025-12-13T17:53:53.57089+01:00","created_by":"bkase"},{"issue_id":"azul-pdt.5","depends_on_id":"azul-pdt.2","type":"blocks","created_at":"2025-12-13T17:55:52.871421+01:00","created_by":"bkase"}]}
{"id":"azul-pdt.6","title":"Verify parallel MCTS achieves target throughput","description":"Run acceptance test to verify CPU parallelism meets performance targets:\n\n```bash\ncargo run --release --features profiling -- \\\n  --num-iters 1 \\\n  --games-per-iter 20 \\\n  --mcts-sims 20 \\\n  --mcts-threads 4 \\\n  --mcts-parallel-mode root \\\n  --no-train \\\n  --no-checkpoints\n```\n\nVerify:\n1. Self-play throughput ≥ 10 games/sec (from ~5-8 games/sec after batching alone)\n2. CPU utilization scales with thread count\n3. No significant regression in policy quality\n\nIf targets not met:\n- Profile to identify locking/contention issues\n- Try different thread counts (match performance cores)\n- Consider tree-parallel as next step\n\nLocation: Run from repo root","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-13T17:54:09.838139+01:00","updated_at":"2025-12-13T17:54:09.838139+01:00","dependencies":[{"issue_id":"azul-pdt.6","depends_on_id":"azul-pdt","type":"parent-child","created_at":"2025-12-13T17:54:09.838706+01:00","created_by":"bkase"},{"issue_id":"azul-pdt.6","depends_on_id":"azul-pdt.3","type":"blocks","created_at":"2025-12-13T17:55:58.014723+01:00","created_by":"bkase"}]}
{"id":"azul-pq1","title":"Use nn::value_and_grad for autodiff instead of finite differences","description":"Current training uses compute_gradients_fd() with finite differences which is slow and only samples 1% of parameters. Replace with mlx-rs nn::value_and_grad() which uses proper autodiff. Depends on azul-5dl.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:38:45.524251+01:00","updated_at":"2025-12-11T00:54:12.372512+01:00","closed_at":"2025-12-11T00:54:12.372512+01:00","dependencies":[{"issue_id":"azul-pq1","depends_on_id":"azul-5dl","type":"blocks","created_at":"2025-12-11T00:39:32.489515+01:00","created_by":"bkase"}]}
{"id":"azul-q5a","title":"Milestone 3: Micro-benchmarks","description":"Add Criterion-based micro-benchmarks to isolate per-component costs: feature extraction, MCTS search, NN forward, and training step.","status":"closed","priority":2,"issue_type":"epic","created_at":"2025-12-11T00:50:45.793772+01:00","updated_at":"2025-12-11T01:44:28.330914+01:00","closed_at":"2025-12-11T01:44:28.330914+01:00","dependencies":[{"issue_id":"azul-q5a","depends_on_id":"azul-p5c","type":"blocks","created_at":"2025-12-11T00:56:12.530173+01:00","created_by":"bkase"}]}
{"id":"azul-q5a.1","title":"Add Criterion dev dependency","description":"In crates/rl-env/Cargo.toml, add criterion = \"0.5\" to [dev-dependencies]. Add [[bench]] entries for each benchmark file. Configure harness = false for Criterion benchmarks.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:53:54.059192+01:00","updated_at":"2025-12-11T01:39:39.758394+01:00","closed_at":"2025-12-11T01:39:39.758394+01:00","dependencies":[{"issue_id":"azul-q5a.1","depends_on_id":"azul-q5a","type":"parent-child","created_at":"2025-12-11T00:53:54.06073+01:00","created_by":"bkase"}]}
{"id":"azul-q5a.2","title":"Create feature_extractor_bench.rs","description":"Create crates/rl-env/benches/feature_extractor_bench.rs. Benchmark BasicFeatureExtractor::encode() with sample GameState from azul_engine::new_game(). Also benchmark AzulEnv::build_observations(). Measure ns/encode, encode/sec.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:54:00.122408+01:00","updated_at":"2025-12-11T01:39:46.137286+01:00","closed_at":"2025-12-11T01:39:46.137286+01:00","dependencies":[{"issue_id":"azul-q5a.2","depends_on_id":"azul-q5a","type":"parent-child","created_at":"2025-12-11T00:54:00.122979+01:00","created_by":"bkase"},{"issue_id":"azul-q5a.2","depends_on_id":"azul-q5a.1","type":"blocks","created_at":"2025-12-11T00:58:23.681667+01:00","created_by":"bkase"}]}
{"id":"azul-q5a.3","title":"Create mcts_bench.rs","description":"Create crates/rl-env/benches/mcts_bench.rs. Use DummyNet (uniform priors, constant value) to remove NN cost. Fixed game state from AzulEnv::reset(). Benchmark run_search with num_simulations: 10, 20, 50, 100. Output: ms/search, simulations/sec.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:54:06.079874+01:00","updated_at":"2025-12-11T01:39:53.405459+01:00","closed_at":"2025-12-11T01:39:53.405459+01:00","dependencies":[{"issue_id":"azul-q5a.3","depends_on_id":"azul-q5a","type":"parent-child","created_at":"2025-12-11T00:54:06.080409+01:00","created_by":"bkase"},{"issue_id":"azul-q5a.3","depends_on_id":"azul-q5a.1","type":"blocks","created_at":"2025-12-11T00:58:29.664574+01:00","created_by":"bkase"}]}
{"id":"azul-q5a.4","title":"Create net_bench.rs","description":"Create crates/rl-env/benches/net_bench.rs. Instantiate AlphaZeroNet with obs_size from BasicFeatureExtractor(2).obs_size(), hidden_size=128. Create random Array batch [batch_size, obs_size]. Benchmark forward_batch with batch_size: 1, 32, 64, 256. Isolate MLX forward pass cost.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:54:12.309666+01:00","updated_at":"2025-12-11T01:39:59.816302+01:00","closed_at":"2025-12-11T01:39:59.816302+01:00","dependencies":[{"issue_id":"azul-q5a.4","depends_on_id":"azul-q5a","type":"parent-child","created_at":"2025-12-11T00:54:12.310214+01:00","created_by":"bkase"},{"issue_id":"azul-q5a.4","depends_on_id":"azul-q5a.1","type":"blocks","created_at":"2025-12-11T00:58:36.122029+01:00","created_by":"bkase"}]}
{"id":"azul-q5a.5","title":"Create training_step_bench.rs","description":"Create crates/rl-env/benches/training_step_bench.rs. Use Trainer with small replay buffer pre-populated with synthetic TrainingExamples. Use stub TrainableModel or simplified version. Benchmark training_step directly for single batch. This will show FD gradients as major cost.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:54:18.493+01:00","updated_at":"2025-12-11T01:40:12.730729+01:00","closed_at":"2025-12-11T01:40:12.730729+01:00","dependencies":[{"issue_id":"azul-q5a.5","depends_on_id":"azul-q5a","type":"parent-child","created_at":"2025-12-11T00:54:18.493551+01:00","created_by":"bkase"},{"issue_id":"azul-q5a.5","depends_on_id":"azul-q5a.1","type":"blocks","created_at":"2025-12-11T00:58:42.104957+01:00","created_by":"bkase"}]}
{"id":"azul-q5a.6","title":"Run and document benchmark results","description":"Execute: cargo bench -p azul-rl-env. Record all benchmark numbers. Document per-component costs in history/benchmark_baseline.md. This creates a menu of costs for optimization targeting.","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-11T00:54:24.55678+01:00","updated_at":"2025-12-11T01:43:50.668169+01:00","closed_at":"2025-12-11T01:43:50.668169+01:00","dependencies":[{"issue_id":"azul-q5a.6","depends_on_id":"azul-q5a","type":"parent-child","created_at":"2025-12-11T00:54:24.557299+01:00","created_by":"bkase"},{"issue_id":"azul-q5a.6","depends_on_id":"azul-q5a.2","type":"blocks","created_at":"2025-12-11T00:58:48.141827+01:00","created_by":"bkase"},{"issue_id":"azul-q5a.6","depends_on_id":"azul-q5a.3","type":"blocks","created_at":"2025-12-11T00:58:54.454863+01:00","created_by":"bkase"},{"issue_id":"azul-q5a.6","depends_on_id":"azul-q5a.4","type":"blocks","created_at":"2025-12-11T00:59:01.128822+01:00","created_by":"bkase"},{"issue_id":"azul-q5a.6","depends_on_id":"azul-q5a.5","type":"blocks","created_at":"2025-12-11T00:59:07.339817+01:00","created_by":"bkase"}]}
{"id":"azul-qgd","title":"Implement eval_parameters using mlx-rs transforms::eval_params","description":"Currently eval_parameters() is empty. Use mlx_rs::transforms::eval_params() to force evaluation of lazy MLX arrays after gradient updates.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:38:55.82575+01:00","updated_at":"2025-12-11T00:44:35.371133+01:00","closed_at":"2025-12-11T00:44:35.371133+01:00"}
{"id":"azul-sic","title":"MLX \u0026 Rust Integration","description":"Set up MLX for learning, Rust bindings, and performance optimization infrastructure","status":"open","priority":2,"issue_type":"epic","created_at":"2025-12-09T21:14:45.219484+01:00","updated_at":"2025-12-09T21:14:45.219484+01:00","labels":["infrastructure","mlx","rust"]}
{"id":"azul-v33","title":"Milestone 2: Training Step Profiling","description":"Profile the training step with focus on finite-difference gradients. Add feature flag to gate FD computation and measure its cost relative to the rest of the pipeline.","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-11T00:50:39.661501+01:00","updated_at":"2025-12-11T01:37:05.803698+01:00","closed_at":"2025-12-11T01:37:05.803698+01:00","dependencies":[{"issue_id":"azul-v33","depends_on_id":"azul-p5c","type":"blocks","created_at":"2025-12-11T00:56:06.307381+01:00","created_by":"bkase"}]}
{"id":"azul-v33.1","title":"Add fd-gradients feature flag","description":"Add optional 'fd-gradients' feature in crates/rl-env/Cargo.toml (default: off). This gates the expensive finite-difference gradient computation. Without this feature, training_step does forward+loss only.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:53:05.157011+01:00","updated_at":"2025-12-11T01:35:14.017935+01:00","closed_at":"2025-12-11T01:35:14.017935+01:00","dependencies":[{"issue_id":"azul-v33.1","depends_on_id":"azul-v33","type":"parent-child","created_at":"2025-12-11T00:53:05.157617+01:00","created_by":"bkase"}]}
{"id":"azul-v33.2","title":"Gate compute_gradients_fd behind feature","description":"In training_step, check cfg!(feature = \"fd-gradients\"). If false: compute loss only (forward once), skip compute_gradients_fd entirely. If true: run FD computation as before. This provides huge speedup when FD is disabled.","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-11T00:53:12.343927+01:00","updated_at":"2025-12-11T01:35:20.222268+01:00","closed_at":"2025-12-11T01:35:20.222268+01:00","dependencies":[{"issue_id":"azul-v33.2","depends_on_id":"azul-v33","type":"parent-child","created_at":"2025-12-11T00:53:12.344417+01:00","created_by":"bkase"},{"issue_id":"azul-v33.2","depends_on_id":"azul-v33.1","type":"blocks","created_at":"2025-12-11T00:57:59.320843+01:00","created_by":"bkase"}]}
{"id":"azul-v33.3","title":"Instrument training_step timing","description":"In training_step function, add Timer for time_training_step_ns. This measures total time per training step including loss computation and gradient updates.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:53:18.290972+01:00","updated_at":"2025-12-11T01:36:08.903684+01:00","closed_at":"2025-12-11T01:36:08.903684+01:00","dependencies":[{"issue_id":"azul-v33.3","depends_on_id":"azul-v33","type":"parent-child","created_at":"2025-12-11T00:53:18.291841+01:00","created_by":"bkase"},{"issue_id":"azul-v33.3","depends_on_id":"azul-v33.2","type":"blocks","created_at":"2025-12-11T00:58:05.279931+01:00","created_by":"bkase"}]}
{"id":"azul-v33.4","title":"Instrument compute_gradients_fd timing","description":"Add Timer for time_fd_grad_ns inside compute_gradients_fd. Also add fd_forward_evals counter increment for each forward_with_params call (should show ~2400 evals per training step).","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:53:24.347353+01:00","updated_at":"2025-12-11T01:36:19.285512+01:00","closed_at":"2025-12-11T01:36:19.285512+01:00","dependencies":[{"issue_id":"azul-v33.4","depends_on_id":"azul-v33","type":"parent-child","created_at":"2025-12-11T00:53:24.347912+01:00","created_by":"bkase"},{"issue_id":"azul-v33.4","depends_on_id":"azul-v33.2","type":"blocks","created_at":"2025-12-11T00:58:11.473641+01:00","created_by":"bkase"}]}
{"id":"azul-v33.5","title":"Run comparative FD profiling","description":"Run two profiling sessions: (1) Without fd-gradients: cargo run --release --features profiling -- --num-iters 2 --games-per-iter 2 --training-steps 10 --mcts-sims 20. (2) With fd-gradients: cargo run --release --features 'profiling,fd-gradients' -- ... Compare time_training_ns, fd_forward_evals, nn_batch_forwards. Document FD cost ratio.","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-11T00:53:30.553422+01:00","updated_at":"2025-12-11T01:36:59.445514+01:00","closed_at":"2025-12-11T01:36:59.445514+01:00","dependencies":[{"issue_id":"azul-v33.5","depends_on_id":"azul-v33","type":"parent-child","created_at":"2025-12-11T00:53:30.553989+01:00","created_by":"bkase"},{"issue_id":"azul-v33.5","depends_on_id":"azul-v33.4","type":"blocks","created_at":"2025-12-11T00:58:17.534136+01:00","created_by":"bkase"}]}
{"id":"azul-voz","title":"Add --resume flag to continue training from checkpoint","description":"Allow resuming training from a saved checkpoint.\n\n**Current state:**\n- Checkpoints save neural network weights via safetensors\n- `load()` method exists on AlphaZeroNet but is unused\n\n**Implementation:**\n1. Add `--resume \u003ccheckpoint_path\u003e` CLI flag to main.rs\n2. Call `agent.load(\u0026checkpoint_path)` before training starts  \n3. Optionally parse iteration number from checkpoint filename (e.g., checkpoint_000050.bin → start at iter 50)\n4. Consider saving/loading replay buffer state for full resumption\n\n**Nice to have:**\n- Auto-detect latest checkpoint in checkpoint_dir\n- Save training metadata (iteration, loss history) alongside weights","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-12-11T01:41:18.435056+01:00","updated_at":"2025-12-11T01:48:40.254792+01:00","closed_at":"2025-12-11T01:48:40.254792+01:00"}
{"id":"azul-zfs","title":"Batched NN Inference for AlphaZero MCTS","description":"","status":"closed","priority":1,"issue_type":"epic","created_at":"2025-12-13T17:46:53.305224+01:00","updated_at":"2025-12-13T23:59:13.894228+01:00","closed_at":"2025-12-13T23:59:13.894228+01:00"}
{"id":"azul-zfs.1","title":"Add nn_batch_size and virtual_loss to MctsConfig","description":"Add new config fields to MctsConfig struct in mcts.rs:\n\n```rust\npub struct MctsConfig {\n    // existing fields...\n    \n    /// How many leaf positions to evaluate per NN batch.\n    /// If 1 =\u003e sequential but still uses predict_batch(B=1) path.\n    pub nn_batch_size: usize,\n    \n    /// Virtual loss magnitude for in-flight simulations.\n    /// Typical: 1.0 when values are in [-1, 1].\n    pub virtual_loss: f32,\n}\n```\n\nUpdate Default impl:\n- nn_batch_size: 32 (good starting point)\n- virtual_loss: 1.0 (good starting point)\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:47:09.149261+01:00","updated_at":"2025-12-13T23:35:21.405737+01:00","closed_at":"2025-12-13T23:35:21.405737+01:00","dependencies":[{"issue_id":"azul-zfs.1","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:47:09.149826+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.10","title":"Add mcts_nn_batches and mcts_nn_positions profiling counters","description":"Add new profiling counters to track batching effectiveness:\n\nIn profiling.rs, add to Counters:\n```rust\npub mcts_nn_batches: AtomicU64,    // number of predict_batch calls\npub mcts_nn_positions: AtomicU64,  // total positions evaluated (sum of batch sizes)\n```\n\nUpdate mcts_nn_evals semantics to mean 'positions evaluated' (same as mcts_nn_positions).\n\nIn print_summary(), add:\n- Average batch size = mcts_nn_positions / mcts_nn_batches\n- Positions per second\n\nThis lets us verify batching is working and measure its effectiveness.\n\nLocation: crates/rl-env/src/profiling.rs","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:49:58.281748+01:00","updated_at":"2025-12-13T23:38:28.204682+01:00","closed_at":"2025-12-13T23:38:28.204682+01:00","dependencies":[{"issue_id":"azul-zfs.10","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:49:58.282298+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.11","title":"Implement DummyNet::predict_batch for tests","description":"Fix DummyNet::predict_batch which currently panics with unimplemented!():\n\n```rust\nfn predict_batch(\u0026mut self, obs_batch: \u0026Array) -\u003e (Array, Array) {\n    let batch_size = obs_batch.shape()[0] as usize;\n\n    let mut policies = Vec::with_capacity(batch_size * ACTION_SPACE_SIZE);\n    for _ in 0..batch_size {\n        policies.extend_from_slice(\u0026self.priors);\n    }\n\n    let values = vec![self.value; batch_size];\n\n    let policy_arr = Array::from_slice(\u0026policies, \u0026[batch_size as i32, ACTION_SPACE_SIZE as i32]);\n    let values_arr = Array::from_slice(\u0026values, \u0026[batch_size as i32]);\n    (policy_arr, values_arr)\n}\n```\n\nThis is required because MCTS now uses predict_batch exclusively.\nThe DummyNet just tiles its uniform priors and constant value across the batch.\n\nLocation: crates/rl-env/src/mcts.rs (in #[cfg(test)] mod tests)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:50:14.456977+01:00","updated_at":"2025-12-13T23:40:53.744443+01:00","closed_at":"2025-12-13T23:40:53.744443+01:00","dependencies":[{"issue_id":"azul-zfs.11","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:50:14.457761+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.12","title":"Update test_mcts_config_default for new fields","description":"Update test_mcts_config_default to assert defaults for new fields:\n\n```rust\n#[test]\nfn test_mcts_config_default() {\n    let cfg = MctsConfig::default();\n    assert_eq!(cfg.num_simulations, 256);\n    assert_eq!(cfg.cpuct, 1.5);\n    // ... existing asserts ...\n    \n    // NEW: assert batching defaults\n    assert_eq!(cfg.nn_batch_size, 32);\n    assert_eq!(cfg.virtual_loss, 1.0);\n}\n```\n\nLocation: crates/rl-env/src/mcts.rs (in #[cfg(test)] mod tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:50:28.210911+01:00","updated_at":"2025-12-13T23:41:21.403708+01:00","closed_at":"2025-12-13T23:41:21.403708+01:00","dependencies":[{"issue_id":"azul-zfs.12","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:50:28.211607+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.12","depends_on_id":"azul-zfs.1","type":"blocks","created_at":"2025-12-13T23:31:26.590367+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.13","title":"Add batched MCTS invariant test","description":"Add a new test that runs search with nn_batch_size \u003e 1 and verifies invariants:\n\n```rust\n#[test]\nfn test_batched_mcts_invariants() {\n    let mut rng = SmallRng::seed_from_u64(42);\n    let state = new_game(2, \u0026mut rng);\n    \n    let config = MctsConfig {\n        num_simulations: 50,\n        nn_batch_size: 8,  // batched!\n        virtual_loss: 1.0,\n        ..Default::default()\n    };\n    \n    let features = BasicFeatureExtractor::new(2);\n    let net = DummyNet::new();\n    let mut agent = AlphaZeroMctsAgent::new(config, features, net);\n    \n    let (action, policy) = agent.select_action_and_policy(\u0026state, \u0026mut rng);\n    \n    // Policy sums to ~1 (after masking and renormalization)\n    let policy_sum: f32 = policy.iter().sum();\n    assert!((policy_sum - 1.0).abs() \u003c 0.01, \"Policy should sum to 1\");\n    \n    // Action is legal\n    let legal = legal_actions(\u0026state);\n    let action_decoded = ActionEncoder::decode(action);\n    assert!(legal.contains(\u0026action_decoded), \"Selected action must be legal\");\n}\n```\n\nLocation: crates/rl-env/src/mcts.rs (in #[cfg(test)] mod tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:50:44.858907+01:00","updated_at":"2025-12-13T23:52:03.308228+01:00","closed_at":"2025-12-13T23:52:03.308228+01:00","dependencies":[{"issue_id":"azul-zfs.13","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:50:44.85975+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.13","depends_on_id":"azul-zfs.11","type":"blocks","created_at":"2025-12-13T17:55:18.267585+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.14","title":"Add scratch buffers to reduce allocations in process_batch","description":"Once batching works, allocator noise may dominate. Add reusable scratch buffers:\n\nAdd fields to AlphaZeroMctsAgent or use local vars in run_search:\n```rust\nlet mut obs_scratch: Vec\u003cf32\u003e = Vec::with_capacity(batch_size * obs_size);\nlet mut leaf_to_slot: HashMap\u003cNodeIdx, usize\u003e = HashMap::with_capacity(batch_size);\nlet mut unique_leafs: Vec\u003cNodeIdx\u003e = Vec::with_capacity(batch_size);\nlet mut sims_scratch: Vec\u003cPendingSim\u003e = Vec::with_capacity(batch_size);\n```\n\nIn process_batch, use clear() instead of reallocating:\n```rust\nobs_scratch.clear();\nleaf_to_slot.clear();\nunique_leafs.clear();\n// ... reuse for this batch ...\n```\n\nThis eliminates per-batch allocations which can add up over many simulations.\n\nPriority: Do this AFTER batching is working and profiled.\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-13T17:51:00.805991+01:00","updated_at":"2025-12-13T23:56:13.785207+01:00","closed_at":"2025-12-13T23:56:13.785207+01:00","dependencies":[{"issue_id":"azul-zfs.14","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:51:00.807061+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.14","depends_on_id":"azul-zfs.8","type":"blocks","created_at":"2025-12-13T23:31:31.740692+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.15","title":"Expose --mcts-nn-batch-size and --mcts-virtual-loss CLI flags","description":"Add CLI flags to control batching parameters:\n\nIn src/main.rs parse_args():\n```rust\n--mcts-nn-batch-size \u003cN\u003e  // default: 32\n--mcts-virtual-loss \u003cF\u003e   // default: 1.0\n```\n\nWire these through to MctsConfig when constructing the agent.\n\nThis allows tuning batching behavior without recompiling:\n- nn_batch_size=1 gives sequential behavior (for comparison)\n- Higher batch sizes may improve GPU utilization\n- Virtual loss tuning affects exploration vs exploitation\n\nPriority: Do this AFTER core batching is working.\n\nLocation: src/main.rs","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-13T17:51:14.906274+01:00","updated_at":"2025-12-13T23:53:46.052203+01:00","closed_at":"2025-12-13T23:53:46.052203+01:00","dependencies":[{"issue_id":"azul-zfs.15","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:51:14.907181+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.15","depends_on_id":"azul-zfs.1","type":"blocks","created_at":"2025-12-13T23:31:36.884408+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.16","title":"Remove or feature-gate old create_node and simulate functions","description":"After batched pipeline is working, clean up old code paths:\n\nOption A (preferred): Delete old functions entirely\n- Remove create_node() \n- Remove simulate()\n- Remove any predict_single calls in MCTS path\n\nOption B: Feature-gate for comparison\n- Add feature flag 'sequential-mcts'\n- Keep old code behind #[cfg(feature = \"sequential-mcts\")]\n- Allows A/B comparison of search quality\n\nEither way, ensure:\n- No predict_single calls in default MCTS path\n- Tests still pass\n- Profiling shows 0 mcts_nn_evals from predict_single\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:51:29.954248+01:00","updated_at":"2025-12-13T23:49:43.161437+01:00","closed_at":"2025-12-13T23:49:43.161437+01:00","dependencies":[{"issue_id":"azul-zfs.16","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:51:29.954867+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.16","depends_on_id":"azul-zfs.17","type":"blocks","created_at":"2025-12-13T17:55:28.553309+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.17","title":"Verify batched NN achieves target throughput","description":"Run acceptance test to verify batching meets performance targets:\n\n```bash\ncargo run --release --features profiling -- \\\n  --num-iters 1 \\\n  --games-per-iter 20 \\\n  --mcts-sims 20 \\\n  --no-train \\\n  --no-checkpoints\n```\n\nVerify:\n1. NN eval calls inside MCTS become 0 (no predict_single)\n2. mcts_nn_batches \u003e 0 and mcts_nn_positions ≈ number of expanded nodes\n3. Self-play throughput ≥ 4.5 games/sec (≥2.5x improvement from 1.76 games/sec baseline)\n\nIf targets not met, profile to identify next bottleneck.\n\nLocation: Run from repo root","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:51:45.521192+01:00","updated_at":"2025-12-13T23:46:32.0626+01:00","closed_at":"2025-12-13T23:46:32.0626+01:00","dependencies":[{"issue_id":"azul-zfs.17","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:51:45.521792+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.17","depends_on_id":"azul-zfs.9","type":"blocks","created_at":"2025-12-13T17:55:23.404112+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.18","title":"Add pending bit to ChildEdge for batch diversity (optional)","description":"Optional optimization to improve batch diversity by preventing duplicate leaf selections.\n\n**Problem:** Within a batch, multiple simulations may select the same leaf, wasting batch slots.\n\n**Solution:** Add a pending bit to track in-flight expansions:\n\n```rust\npub struct ChildEdge {\n    pub action_id: ActionId,\n    pub prior: f32,\n    pub visit_count: u32,\n    pub value_sum: f32,\n    pub child: Option\u003cNodeIdx\u003e,\n    \n    /// NEW: true if this edge has a pending expansion in the current batch\n    pub pending: bool,\n}\n```\n\n**Usage in select_child:**\n- Skip or heavily penalize edges with pending=true\n- This forces simulations to explore different paths\n\n**Lifecycle:**\n1. When select_leaf picks an unexpanded edge: set pending=true\n2. After process_batch expands the edge: set pending=false\n\n**When to implement:**\n- Only if profiling shows significant duplicate leaves in batches\n- Virtual loss already helps, this is additional\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":3,"issue_type":"task","created_at":"2025-12-13T17:54:27.06042+01:00","updated_at":"2025-12-13T23:58:50.333079+01:00","closed_at":"2025-12-13T23:58:50.333079+01:00","dependencies":[{"issue_id":"azul-zfs.18","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:54:27.061739+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.18","depends_on_id":"azul-zfs.7","type":"blocks","created_at":"2025-12-13T23:31:42.025384+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.2","title":"Add nn_value field to Node struct","description":"Add optional nn_value field to Node struct to store the NN-predicted value at expansion time.\n\n```rust\npub struct Node {\n    pub state: GameState,\n    pub to_play: PlayerIdx,\n    pub is_terminal: bool,\n    pub children: Vec\u003cChildEdge\u003e,\n    pub visit_count: u32,\n    \n    /// NEW: value predicted when the node was expanded.\n    pub nn_value: Option\u003cf32\u003e,\n}\n```\n\nInitialize nn_value: None for stubs, Some(value) after expansion.\n\nThis avoids re-evaluating value for expanded nodes and is helpful for debugging.\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:47:22.992472+01:00","updated_at":"2025-12-13T23:36:03.503299+01:00","closed_at":"2025-12-13T23:36:03.503299+01:00","dependencies":[{"issue_id":"azul-zfs.2","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:47:22.993588+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.3","title":"Add PendingSim helper struct","description":"Add new helper struct for tracking in-flight simulations:\n\n```rust\nuse std::collections::HashMap;\n\nstruct PendingSim {\n    path: Vec\u003cPathStep\u003e,\n    leaf_idx: NodeIdx,\n    // filled later:\n    leaf_value: f32,\n    // if leaf needs NN (non-terminal):\n    eval_slot: Option\u003cusize\u003e,\n}\n```\n\nThis tracks each simulation from root to leaf, including:\n- The path taken (for backup)\n- Which leaf node was reached\n- The evaluated value (filled after NN batch)\n- Which slot in the batch array (for deduplication)\n\nLocation: crates/rl-env/src/mcts.rs (near top, after imports)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-13T17:47:38.80491+01:00","updated_at":"2025-12-13T23:36:38.112363+01:00","closed_at":"2025-12-13T23:36:38.112363+01:00","dependencies":[{"issue_id":"azul-zfs.3","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:47:38.806417+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.4","title":"Implement create_node_stub function","description":"Replace create_node() with a lightweight stub creation function that does NO NN evaluation:\n\n```rust\nfn create_node_stub(\u0026self, tree: \u0026mut MctsTree, state: GameState) -\u003e NodeIdx {\n    let to_play = state.current_player;\n    let is_terminal = state.phase == Phase::GameOver;\n\n    let node = Node {\n        state,\n        to_play,\n        is_terminal,\n        children: Vec::new(),\n        visit_count: 0,\n        nn_value: None,\n    };\n    let idx = tree.nodes.len() as NodeIdx;\n    tree.nodes.push(node);\n    idx\n}\n```\n\nKey differences from old create_node():\n- No NN evaluation\n- No child expansion (children is empty)\n- nn_value is None\n- Much faster - just allocates the node\n\nThe NN evaluation and expansion happen later in expand_node_from_nn().\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:47:54.098908+01:00","updated_at":"2025-12-13T23:39:04.425503+01:00","closed_at":"2025-12-13T23:39:04.425503+01:00","dependencies":[{"issue_id":"azul-zfs.4","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:47:54.100002+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.5","title":"Implement expand_node_from_nn function","description":"Expand a node given NN outputs (policy logits row + value):\n\n```rust\nfn expand_node_from_nn(\n    \u0026mut self,\n    tree: \u0026mut MctsTree,\n    node_idx: NodeIdx,\n    policy_logits_row: \u0026[f32], // len == ACTION_SPACE_SIZE\n    value: f32,\n) {\n    let node = \u0026mut tree.nodes[node_idx as usize];\n\n    if node.is_terminal {\n        node.nn_value = Some(value);\n        return;\n    }\n\n    // Only expand once\n    if \\!node.children.is_empty() {\n        return;\n    }\n\n    node.nn_value = Some(value);\n\n    let actions = legal_actions(\u0026node.state);\n\n    let mut legal_ids_and_logits: Vec\u003c(ActionId, f32)\u003e = Vec::with_capacity(actions.len());\n    for action in \u0026actions {\n        let id = ActionEncoder::encode(action);\n        legal_ids_and_logits.push((id, policy_logits_row[id as usize]));\n    }\n\n    let priors = softmax(\u0026legal_ids_and_logits);\n\n    node.children = priors.into_iter().map(|(id, prior)| ChildEdge {\n        action_id: id,\n        prior,\n        visit_count: 0,\n        value_sum: 0.0,\n        child: None,\n    }).collect();\n}\n```\n\nThis is the same logic as old create_node() but:\n- Takes pre-computed logits from batch output\n- Stores value in nn_value\n- Idempotent (won't re-expand)\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:48:11.63086+01:00","updated_at":"2025-12-13T23:39:38.54597+01:00","closed_at":"2025-12-13T23:39:38.54597+01:00","dependencies":[{"issue_id":"azul-zfs.5","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:48:11.631385+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.5","depends_on_id":"azul-zfs.2","type":"blocks","created_at":"2025-12-13T17:55:13.118816+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.6","title":"Implement virtual loss helpers","description":"Add functions to apply and revert virtual loss for in-flight simulations:\n\n```rust\nfn apply_virtual_loss(tree: \u0026mut MctsTree, step: \u0026PathStep, vloss: f32) {\n    let node = \u0026mut tree.nodes[step.node_idx as usize];\n    let edge = \u0026mut node.children[step.child_idx];\n\n    // virtual visit\n    edge.visit_count += 1;\n    node.visit_count += 1;\n\n    // penalize Q to discourage collisions\n    edge.value_sum -= vloss;\n}\n\nfn revert_virtual_loss(tree: \u0026mut MctsTree, step: \u0026PathStep, vloss: f32) {\n    let node = \u0026mut tree.nodes[step.node_idx as usize];\n    let edge = \u0026mut node.children[step.child_idx];\n\n    // revert virtual visit\n    edge.visit_count -= 1;\n    node.visit_count -= 1;\n\n    // revert virtual penalty\n    edge.value_sum += vloss;\n}\n\nfn backup_with_virtual_loss(tree: \u0026mut MctsTree, path: \u0026[PathStep], leaf_value: f32, vloss: f32) {\n    let mut value = leaf_value;\n\n    for step in path.iter().rev() {\n        // remove virtual loss for this in-flight sim\n        revert_virtual_loss(tree, step, vloss);\n\n        // apply real backup\n        let node = \u0026mut tree.nodes[step.node_idx as usize];\n        let edge = \u0026mut node.children[step.child_idx];\n\n        edge.visit_count += 1;\n        edge.value_sum += value;\n        node.visit_count += 1;\n\n        value = -value;\n    }\n}\n```\n\nVirtual loss prevents multiple in-flight simulations from taking the same path.\nAdd debug_assert!(edge.visit_count \u003e 0) in revert to catch underflow bugs.\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:48:31.870988+01:00","updated_at":"2025-12-13T23:40:17.639217+01:00","closed_at":"2025-12-13T23:40:17.639217+01:00","dependencies":[{"issue_id":"azul-zfs.6","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:48:31.872038+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.7","title":"Implement select_leaf function","description":"Perform selection while applying virtual loss and creating stub children for unexpanded edges:\n\n```rust\nfn select_leaf(\n    \u0026mut self,\n    tree: \u0026mut MctsTree,\n    root_idx: NodeIdx,\n    rng: \u0026mut impl Rng,\n) -\u003e PendingSim {\n    let mut path: Vec\u003cPathStep\u003e = Vec::new();\n    let mut current_idx = root_idx;\n\n    for _depth in 0..(self.config.max_depth as usize) {\n        let is_terminal;\n        let has_children;\n        {\n            let node = \u0026tree.nodes[current_idx as usize];\n            is_terminal = node.is_terminal;\n            has_children = !node.children.is_empty();\n        }\n\n        if is_terminal || !has_children {\n            break;\n        }\n\n        // choose child via PUCT\n        let child_idx = {\n            let node = \u0026tree.nodes[current_idx as usize];\n            select_child(node, self.config.cpuct)\n        };\n\n        // record and apply virtual loss on the chosen edge\n        let step = PathStep { node_idx: current_idx, child_idx };\n        apply_virtual_loss(tree, \u0026step, self.config.virtual_loss);\n        path.push(step);\n\n        // descend or expand stub\n        let next_child_opt = tree.nodes[current_idx as usize].children[child_idx].child;\n        if let Some(next_idx) = next_child_opt {\n            current_idx = next_idx;\n            continue;\n        }\n\n        // Expand edge by creating child stub node\n        let parent_state = tree.nodes[current_idx as usize].state.clone();\n        let action_id = tree.nodes[current_idx as usize].children[child_idx].action_id;\n        let action = ActionEncoder::decode(action_id);\n\n        let step_result = apply_action(parent_state, action, rng)\n            .expect(\"MCTS should only expand legal actions\");\n\n        let new_idx = self.create_node_stub(tree, step_result.state);\n\n        tree.nodes[current_idx as usize].children[child_idx].child = Some(new_idx);\n\n        current_idx = new_idx;\n        break;\n    }\n\n    PendingSim {\n        path,\n        leaf_idx: current_idx,\n        leaf_value: 0.0,      // filled later\n        eval_slot: None,      // filled later\n    }\n}\n```\n\nKey semantics:\n- Node with children.is_empty() = unexpanded leaf (NN eval candidate)\n- Terminal nodes also have empty children but is_terminal distinguishes them\n- Virtual loss applied along path to prevent collisions\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:48:56.514984+01:00","updated_at":"2025-12-13T23:41:56.934394+01:00","closed_at":"2025-12-13T23:41:56.934394+01:00","dependencies":[{"issue_id":"azul-zfs.7","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:48:56.516028+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.7","depends_on_id":"azul-zfs.6","type":"blocks","created_at":"2025-12-13T17:55:02.817273+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.7","depends_on_id":"azul-zfs.4","type":"blocks","created_at":"2025-12-13T17:55:07.963801+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.8","title":"Implement process_batch function","description":"Process a group of PendingSim with batched NN evaluation:\n\n```rust\nfn process_batch(\n    \u0026mut self,\n    tree: \u0026mut MctsTree,\n    sims: \u0026mut [PendingSim],\n) {\n    // 1) Identify which leaves need NN evaluation; compute terminal ones immediately.\n    let mut unique_leafs: Vec\u003cNodeIdx\u003e = Vec::new();\n    let mut leaf_to_slot: HashMap\u003cNodeIdx, usize\u003e = HashMap::new();\n\n    for sim in sims.iter_mut() {\n        let leaf = \u0026tree.nodes[sim.leaf_idx as usize];\n        if leaf.is_terminal {\n            sim.leaf_value = compute_terminal_value(\u0026leaf.state, leaf.to_play);\n            sim.eval_slot = None;\n        } else {\n            let slot = *leaf_to_slot.entry(sim.leaf_idx).or_insert_with(|| {\n                let s = unique_leafs.len();\n                unique_leafs.push(sim.leaf_idx);\n                s\n            });\n            sim.eval_slot = Some(slot);\n        }\n    }\n\n    // 2) If any NN leaves exist, batch them.\n    if !unique_leafs.is_empty() {\n        let obs_size = self.features.obs_size();\n        let b = unique_leafs.len();\n\n        // Build [B, obs_size] contiguous buffer\n        let mut obs_data: Vec\u003cf32\u003e = Vec::with_capacity(b * obs_size);\n        for \u0026node_idx in \u0026unique_leafs {\n            let node = \u0026tree.nodes[node_idx as usize];\n            let obs = self.features.encode(\u0026node.state, node.to_play);\n            obs_data.extend_from_slice(obs.as_slice::\u003cf32\u003e());\n        }\n\n        let obs_batch = Array::from_slice(\u0026obs_data, \u0026[b as i32, obs_size as i32]);\n\n        // NN inference\n        #[cfg(feature = \"profiling\")]\n        let _t = Timer::new(\u0026PROF.time_mcts_nn_eval_ns);\n        #[cfg(feature = \"profiling\")]\n        {\n            PROF.mcts_nn_batches.fetch_add(1, Ordering::Relaxed);\n            PROF.mcts_nn_evals.fetch_add(b as u64, Ordering::Relaxed);\n        }\n\n        let (policy_logits_batch, values_batch) = self.net.predict_batch(\u0026obs_batch);\n\n        let logits = policy_logits_batch.as_slice::\u003cf32\u003e();\n        let values = values_batch.as_slice::\u003cf32\u003e();\n\n        // 3) Expand each unique leaf using its logits row, and store leaf value.\n        for (slot, \u0026node_idx) in unique_leafs.iter().enumerate() {\n            let value = values[slot];\n            let row_start = slot * ACTION_SPACE_SIZE;\n            let row_end = row_start + ACTION_SPACE_SIZE;\n            let logits_row = \u0026logits[row_start..row_end];\n\n            if tree.nodes[node_idx as usize].children.is_empty() {\n                self.expand_node_from_nn(tree, node_idx, logits_row, value);\n            }\n        }\n\n        // Fill leaf_value for each sim\n        for sim in sims.iter_mut() {\n            if let Some(slot) = sim.eval_slot {\n                sim.leaf_value = values[slot];\n            }\n        }\n    }\n\n    // 4) Backup each simulation result\n    for sim in sims.iter() {\n        backup_with_virtual_loss(tree, \u0026sim.path, sim.leaf_value, self.config.virtual_loss);\n    }\n}\n```\n\nKey features:\n- Deduplicates leaves (multiple sims may reach same leaf)\n- Single predict_batch call for all unique leaves\n- Terminal nodes get immediate value, skip NN\n- Expands all leaves from batch output\n- Backs up all sims with virtual loss reversion\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:49:26.194235+01:00","updated_at":"2025-12-13T23:42:41.312369+01:00","closed_at":"2025-12-13T23:42:41.312369+01:00","dependencies":[{"issue_id":"azul-zfs.8","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:49:26.195163+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.8","depends_on_id":"azul-zfs.6","type":"blocks","created_at":"2025-12-13T17:54:52.528943+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.8","depends_on_id":"azul-zfs.5","type":"blocks","created_at":"2025-12-13T17:54:57.667185+01:00","created_by":"bkase"}]}
{"id":"azul-zfs.9","title":"Rewrite run_search to use batched pipeline","description":"Replace run_search() body with batched simulation pipeline:\n\n1. Create root stub + expand with predict_batch(B=1)\n2. Add Dirichlet noise to root\n3. Run simulations in batches using select_leaf + process_batch\n4. Build policy from root visits\n\nKey changes:\n- Root expansion uses predict_batch instead of predict_single\n- Main loop runs nn_batch_size simulations per iteration\n- All NN calls go through predict_batch\n\nAfter this change:\n- simulate() and old create_node() can be deleted/feature-flagged\n- All NN inference inside MCTS uses predict_batch\n- Zero predict_single calls in MCTS path\n\nSee batched-nn.md section 6.1.6 for full implementation.\n\nLocation: crates/rl-env/src/mcts.rs","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-13T17:49:43.530063+01:00","updated_at":"2025-12-13T23:45:30.212931+01:00","closed_at":"2025-12-13T23:45:30.212931+01:00","dependencies":[{"issue_id":"azul-zfs.9","depends_on_id":"azul-zfs","type":"parent-child","created_at":"2025-12-13T17:49:43.531277+01:00","created_by":"bkase"},{"issue_id":"azul-zfs.9","depends_on_id":"azul-zfs.8","type":"blocks","created_at":"2025-12-13T17:54:47.383433+01:00","created_by":"bkase"}]}
